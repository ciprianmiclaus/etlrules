{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ETLrules \u00b6 A python rule engine operating with data frames aimed at the financial services Free software: MIT Documentation: https://ciprianmiclaus.github.io/etlrules/ Features \u00b6 TODO Credits \u00b6 This package was created with the ppw tool. For more information, please visit the project page .","title":"Home"},{"location":"#etlrules","text":"A python rule engine operating with data frames aimed at the financial services Free software: MIT Documentation: https://ciprianmiclaus.github.io/etlrules/","title":"ETLrules"},{"location":"#features","text":"TODO","title":"Features"},{"location":"#credits","text":"This package was created with the ppw tool. For more information, please visit the project page .","title":"Credits"},{"location":"api/","text":"Top-level package for ETLrules. backends special \u00b6 common special \u00b6 basic \u00b6 RulesBlock ( UnaryOpBaseRule ) \u00b6 Groups rules into encapsulated blocks or units of rules that achieve one thing. Blocks are reusable and encapsulated to reduce complexity. Parameters: Name Type Description Default rules Iterable[etlrules.rule.BaseRule] An iterable of rules which are part of this block. The first rule in the block will take its input from the named_input of the RulesBlock (if any, if not from the main output of the previous rule). The last rule in the block will publish the output as the named_output of the RulesBlock (if any, or the main output of the block). Any named outputs in the block are not exposed to the rules outside of the block (proper encapsulation). required Common params: !!! named_input \"Which dataframe to use as the input. Optional.\" When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. !!! named_output \"Give the output of this rule a name so it can be used by another rule as a named input. Optional.\" When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. !!! name \"Give the rule a name. Optional.\" Named rules are more descriptive as to what they're trying to do/the intent. !!! description \"Describe in detail what the rules does, how it does it. Optional.\" Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Source code in etlrules/backends/common/basic.py class RulesBlock ( UnaryOpBaseRule ): \"\"\" Groups rules into encapsulated blocks or units of rules that achieve one thing. Blocks are reusable and encapsulated to reduce complexity. Params: rules: An iterable of rules which are part of this block. The first rule in the block will take its input from the named_input of the RulesBlock (if any, if not from the main output of the previous rule). The last rule in the block will publish the output as the named_output of the RulesBlock (if any, or the main output of the block). Any named outputs in the block are not exposed to the rules outside of the block (proper encapsulation). Common params: named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True \"\"\" def __init__ ( self , rules : Iterable [ BaseRule ], named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): self . _rules = [ rule for rule in rules ] assert self . _rules , \"RulesBlock: Empty rules set provided.\" assert all ( isinstance ( rule , BaseRule ) for rule in self . _rules ), [ rule for rule in self . _rules if not isinstance ( rule , BaseRule )] assert self . _rules [ 0 ] . named_input is None , \"First rule in a RulesBlock must consume the main input/output\" assert self . _rules [ - 1 ] . named_input is None , \"Last rule in a RulesBlock must produce the main output\" super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) def apply ( self , data ): super () . apply ( data ) data2 = RuleData ( main_input = self . _get_input_df ( data ), named_inputs = { k : v for k , v in data . get_named_outputs ()}, strict = self . strict ) for rule in self . _rules : rule . apply ( data2 ) self . _set_output_df ( data , data2 . get_main_output ()) def to_dict ( self ): dct = super () . to_dict () dct [ self . __class__ . __name__ ][ \"rules\" ] = [ rule . to_dict () for rule in self . _rules ] return dct @classmethod def from_dict ( cls , dct , backend ): dct = dct [ \"RulesBlock\" ] rules = [ BaseRule . from_dict ( rule , backend ) for rule in dct . get ( \"rules\" , ())] kwargs = { k : v for k , v in dct . items () if k != \"rules\" } return cls ( rules = rules , ** kwargs ) pandas special \u00b6 aggregate \u00b6 AggregateRule ( UnaryOpBaseRule ) \u00b6 Performs a SQL-like groupby and aggregation. It takes a list of columns to group by and the result will have one row for each unique combination of values in the group_by columns. The rest of the columns (not in the group_by) can be aggregated using either pre-defined aggregations or using custom python expressions. Parameters: Name Type Description Default group_by Iterable[str] A list of columns to group the result by required aggregations Optional[Mapping[str, str]] A mapping {column_name: aggregation_function} which specifies how to aggregate columns which are not in the group_by list. The following list of aggregation functions are supported:: 1 2 3 4 5 6 7 8 9 10 11 min: minimum of the values in the group max: minimum of the values in the group mean: The mathematical mean value in the group count: How many values are in the group, including NA countNoNA: How many values are in the group, excluding NA sum: The sum of the values in the group first: The first value in the group last: The last value in the group list: Produces a python list with all the values in the group, excluding NA tuple: Like list above but produces a tuple csv: Produces a comma separated string of values, exluding NA None aggregation_expressions Optional[Mapping[str, str]] A mapping {column_name: aggregation_expression} which specifies how to aggregate columns which are not in the group_by list. The aggregation expression is a string representing a valid Python expression which gets evaluated. The input will be in a variable values . isnull can be used to filter out NA. Example:: 1 2 3 {\"C\": \"';'.join(str(v) for v in values if not isnull(v))\"} The above aggregates the column C by producing a ; separated string of values in the group, excluding NA. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ColumnAlreadyExistsError raised if a column appears in multiple places in group_by/aggregations/aggregation_expressions. ExpressionSyntaxError raised if any aggregation expression (if any are passed in) has a Python syntax error. MissingColumnError raised in strict mode only if a column specified in aggregations or aggregation_expressions is missing from the input dataframe. ValueError raised if a column in aggregations is trying to be aggregated using an unknown aggregate function TypeError raised if an operation is not supported between the types involved NameError raised if an unknown variable is used Note Other Python exceptions can be raised when custom aggregation expressions are used, depending on what the expression is doing. Note Any columns not in the group_by list and not present in either aggregations or aggregation_expressions will be dropped from the result. Source code in etlrules/backends/pandas/aggregate.py class AggregateRule ( UnaryOpBaseRule ): \"\"\" Performs a SQL-like groupby and aggregation. It takes a list of columns to group by and the result will have one row for each unique combination of values in the group_by columns. The rest of the columns (not in the group_by) can be aggregated using either pre-defined aggregations or using custom python expressions. Args: group_by: A list of columns to group the result by aggregations: A mapping {column_name: aggregation_function} which specifies how to aggregate columns which are not in the group_by list. The following list of aggregation functions are supported:: min: minimum of the values in the group max: minimum of the values in the group mean: The mathematical mean value in the group count: How many values are in the group, including NA countNoNA: How many values are in the group, excluding NA sum: The sum of the values in the group first: The first value in the group last: The last value in the group list: Produces a python list with all the values in the group, excluding NA tuple: Like list above but produces a tuple csv: Produces a comma separated string of values, exluding NA aggregation_expressions: A mapping {column_name: aggregation_expression} which specifies how to aggregate columns which are not in the group_by list. The aggregation expression is a string representing a valid Python expression which gets evaluated. The input will be in a variable `values`. `isnull` can be used to filter out NA. Example:: {\"C\": \"';'.join(str(v) for v in values if not isnull(v))\"} The above aggregates the column C by producing a ; separated string of values in the group, excluding NA. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ColumnAlreadyExistsError: raised if a column appears in multiple places in group_by/aggregations/aggregation_expressions. ExpressionSyntaxError: raised if any aggregation expression (if any are passed in) has a Python syntax error. MissingColumnError: raised in strict mode only if a column specified in aggregations or aggregation_expressions is missing from the input dataframe. ValueError: raised if a column in aggregations is trying to be aggregated using an unknown aggregate function TypeError: raised if an operation is not supported between the types involved NameError: raised if an unknown variable is used Note: Other Python exceptions can be raised when custom aggregation expressions are used, depending on what the expression is doing. Note: Any columns not in the group_by list and not present in either aggregations or aggregation_expressions will be dropped from the result. \"\"\" AGGREGATIONS = { \"min\" : \"min\" , \"max\" : \"max\" , \"mean\" : \"mean\" , \"count\" : \"size\" , \"countNoNA\" : \"count\" , \"sum\" : \"sum\" , \"first\" : \"first\" , \"last\" : \"last\" , \"list\" : lambda values : [ value for value in values if not isnull ( value )], \"tuple\" : lambda values : tuple ( value for value in values if not isnull ( value )), \"csv\" : lambda values : \",\" . join ( str ( elem ) for elem in values if not isnull ( elem )), } EXCLUDE_FROM_COMPARE = ( '_aggs' ,) def __init__ ( self , group_by : Iterable [ str ], aggregations : Optional [ Mapping [ str , str ]] = None , aggregation_expressions : Optional [ Mapping [ str , str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . group_by = [ col for col in group_by ] assert aggregations or aggregation_expressions , \"aggregations or aggregation_expressions must be specified.\" for col , agg_func in ( aggregations or {}) . items (): if col in self . group_by : raise ColumnAlreadyExistsError ( f \"Column { col } appears in group_by and cannot be aggregated.\" ) if agg_func not in self . AGGREGATIONS : raise ValueError ( f \"' { agg_func } ' is not a supported aggregation function.\" ) self . aggregations = { key : agg_func for key , agg_func in ( aggregations or {}) . items ()} self . aggregation_expressions = { key : value for key , value in ( aggregation_expressions or {}) . items ()} self . _aggs = {} if self . aggregations : self . _aggs . update ({ key : self . AGGREGATIONS [ agg_func ] for key , agg_func in ( aggregations or {}) . items ()}) if self . aggregation_expressions : for col , agg_expr in self . aggregation_expressions . items (): if col in self . group_by : raise ColumnAlreadyExistsError ( f \"Column { col } appears in group_by and cannot be aggregated.\" ) if col in self . _aggs : raise ColumnAlreadyExistsError ( f \"Column { col } is already being aggregated.\" ) try : _ast_expr = ast . parse ( agg_expr , filename = f ' { col } _expression.py' , mode = 'eval' ) _compiled_expr = compile ( _ast_expr , filename = f ' { col } _expression.py' , mode = 'eval' ) self . _aggs [ col ] = lambda values , bound_compiled_expr = _compiled_expr : eval ( bound_compiled_expr , { 'isnull' : isnull }, { 'values' : values }) except SyntaxError as exc : raise ExpressionSyntaxError ( f \"Error in aggregation expression for column ' { col } ': ' { agg_expr } ': { str ( exc ) } \" ) def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) df_columns_set = set ( df . columns ) if not set ( self . _aggs ) <= df_columns_set : if self . strict : raise MissingColumnError ( f \"Missimg columns to aggregate by: { set ( self . _aggs ) - df_columns_set } \" ) aggs = { col : agg for col , agg in self . _aggs . items () if col in df_columns_set } else : aggs = self . _aggs df = df . groupby ( by = self . group_by , as_index = False , dropna = False ) . agg ( aggs ) self . _set_output_df ( data , df ) basic \u00b6 DedupeRule ( UnaryOpBaseRule ) \u00b6 De-duplicates by dropping duplicates using a set of columns to determine the duplicates. It has logic to keep the first, last or none of the duplicate in a set of duplicates. Parameters: Name Type Description Default columns Iterable[str] A subset of columns in the data frame which are used to determine the set of duplicates. Any rows that have the same values in these columns are considered to be duplicates. required keep Literal['first', 'last', 'none'] What to keep in the de-duplication process. One of: first: keeps the first row in the duplicate set last: keeps the last row in the duplicate set none: drops all the duplicates 'first' named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised when a column specified to deduplicate on doesn't exist in the input data frame. Note MissingColumnError is raised in both strict and non-strict modes. This is because the rule cannot operate reliably without a correct set of columns. Source code in etlrules/backends/pandas/basic.py class DedupeRule ( UnaryOpBaseRule ): \"\"\" De-duplicates by dropping duplicates using a set of columns to determine the duplicates. It has logic to keep the first, last or none of the duplicate in a set of duplicates. Args: columns: A subset of columns in the data frame which are used to determine the set of duplicates. Any rows that have the same values in these columns are considered to be duplicates. keep: What to keep in the de-duplication process. One of: first: keeps the first row in the duplicate set last: keeps the last row in the duplicate set none: drops all the duplicates named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised when a column specified to deduplicate on doesn't exist in the input data frame. Note: MissingColumnError is raised in both strict and non-strict modes. This is because the rule cannot operate reliably without a correct set of columns. \"\"\" KEEP_FIRST = 'first' KEEP_LAST = 'last' KEEP_NONE = 'none' ALL_KEEPS = ( KEEP_FIRST , KEEP_LAST , KEEP_NONE ) def __init__ ( self , columns : Iterable [ str ], keep : Literal [ KEEP_FIRST , KEEP_LAST , KEEP_NONE ] = KEEP_FIRST , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . columns = [ col for col in columns ] assert all ( isinstance ( col , str ) for col in self . columns ), \"DedupeRule: columns must be strings\" assert keep in self . ALL_KEEPS , f \"DedupeRule: keep must be one of: { self . ALL_KEEPS } \" self . keep = False if keep == DedupeRule . KEEP_NONE else keep def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) if not set ( self . columns ) <= set ( df . columns ): raise MissingColumnError ( f \"Missing column(s) to dedupe on: { set ( self . columns ) - set ( df . columns ) } \" ) df = df . drop_duplicates ( subset = self . columns , keep = self . keep , ignore_index = True ) self . _set_output_df ( data , df ) ProjectRule ( BaseProjectRule , PandasRuleValidationMixin ) \u00b6 Reshapes the data frame to keep, eliminate or re-order the set of columns. Parameters: Name Type Description Default columns Iterable[str] The list of columns to keep or eliminate from the data frame. The order of column names will be reflected in the result data frame, so this rule can be used to re-order columns. required exclude bool When set to True, the columns in the columns arg will be excluded from the data frame. Boolean. Default: False In strict mode, if any column specified in the columns arg doesn't exist in the input data frame, a MissingColumnError exception is raised. In non strict mode, the missing columns are ignored. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised in strict mode only, if any columns are missing from the input data frame. Source code in etlrules/backends/pandas/basic.py class ProjectRule ( BaseProjectRule , PandasRuleValidationMixin ): \"\"\" Reshapes the data frame to keep, eliminate or re-order the set of columns. Args: columns (Iterable[str]): The list of columns to keep or eliminate from the data frame. The order of column names will be reflected in the result data frame, so this rule can be used to re-order columns. exclude (bool): When set to True, the columns in the columns arg will be excluded from the data frame. Boolean. Default: False In strict mode, if any column specified in the columns arg doesn't exist in the input data frame, a MissingColumnError exception is raised. In non strict mode, the missing columns are ignored. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only, if any columns are missing from the input data frame. \"\"\" def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) remaining_columns = self . _get_remaining_columns ( df . columns ) df = df [ remaining_columns ] self . _set_output_df ( data , df ) RenameRule ( UnaryOpBaseRule ) \u00b6 Renames a set of columns in the data frame. Parameters: Name Type Description Default mapper Mapping[str, str] A dictionary of old names (keys) and new names (values) to be used for the rename operation The order of column names will be reflected in the result data frame, so this rule can be used to re-order columns. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only, if any columns (keys) are missing from the input data frame. Source code in etlrules/backends/pandas/basic.py class RenameRule ( UnaryOpBaseRule ): \"\"\" Renames a set of columns in the data frame. Args: mapper: A dictionary of old names (keys) and new names (values) to be used for the rename operation The order of column names will be reflected in the result data frame, so this rule can be used to re-order columns. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only, if any columns (keys) are missing from the input data frame. \"\"\" def __init__ ( self , mapper : Mapping [ str , str ], named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): assert isinstance ( mapper , dict ), \"mapper needs to be a dict {old_name:new_name}\" assert all ( isinstance ( key , str ) and isinstance ( val , str ) for key , val in mapper . items ()), \"mapper needs to be a dict {old_name:new_name} where the names are str\" super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . mapper = mapper def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) if self . strict : if not set ( self . mapper . keys ()) <= set ( df . columns ): raise MissingColumnError ( f \"Missing columns to rename: { set ( self . mapper . keys ()) - set ( df . columns ) } \" ) df = df . rename ( columns = self . mapper ) self . _set_output_df ( data , df ) ReplaceRule ( BaseAssignRule ) \u00b6 Replaces some some values (or regular expressions) with another set of values (or regular expressions) in a set of columns. Basic usage:: 1 2 3 4 5 6 7 # replaces A with new_A and b with new_b in col_A, col_B and col_C rule = ReplaceRule([\"col_A\", \"col_B\", \"col_C\"], values=[\"A\", \"b\"], new_values=[\"new_A\", \"new_b\"]) rule.apply(data) # replaces 1 with 3 and 2 with 4 in the col_I column rule = ReplaceRule([\"col_I\"], values=[1, 2], new_values=[3, 4]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required values Iterable[Union[int, float, str]] A sequence of values to replace. Regular expressions can be used to match values more widely, in which case, the regex parameter must be set to True. Values can be any supported types but they should match the type of the columns. required new_values Iterable[Union[int, float, str]] A sequence of the same length as values. Each value within new_values will replace the corresponding value in values (at the same index). New values can be any supported types but they should match the type of the columns. required regex True if all the values and new_values are to be interpreted as regular expressions. Default: False. regex=True is only applicable to string columns. False output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/basic.py class ReplaceRule ( BaseAssignRule ): \"\"\" Replaces some some values (or regular expressions) with another set of values (or regular expressions) in a set of columns. Basic usage:: # replaces A with new_A and b with new_b in col_A, col_B and col_C rule = ReplaceRule([\"col_A\", \"col_B\", \"col_C\"], values=[\"A\", \"b\"], new_values=[\"new_A\", \"new_b\"]) rule.apply(data) # replaces 1 with 3 and 2 with 4 in the col_I column rule = ReplaceRule([\"col_I\"], values=[1, 2], new_values=[3, 4]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. values: A sequence of values to replace. Regular expressions can be used to match values more widely, in which case, the regex parameter must be set to True. Values can be any supported types but they should match the type of the columns. new_values: A sequence of the same length as values. Each value within new_values will replace the corresponding value in values (at the same index). New values can be any supported types but they should match the type of the columns. regex: True if all the values and new_values are to be interpreted as regular expressions. Default: False. regex=True is only applicable to string columns. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , columns : Iterable [ str ], values : Iterable [ Union [ int , float , str ]], new_values : Iterable [ Union [ int , float , str ]], regex = False , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . values = [ val for val in values ] self . new_values = [ val for val in new_values ] assert len ( self . values ) == len ( self . new_values ), \"values and new_values must be of the same length.\" assert self . values , \"values must not be empty.\" self . regex = regex def do_apply ( self , col ): return col . replace ( to_replace = self . values , value = self . new_values , regex = self . regex ) SortRule ( UnaryOpBaseRule ) \u00b6 Sort the input dataframe by the given columns, either ascending or descending. Parameters: Name Type Description Default sort_by Iterable[str] Either a single column speified as a string or a list or tuple of columns to sort by required ascending Union[bool, Iterable[bool]] Whether to sort ascending or descending. Boolean. Default: True True named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Note When multiple columns are specified, the first column decides the sort order. For any rows that have the same value in the first column, the second column is used to decide the sort order within that group and so on. Source code in etlrules/backends/pandas/basic.py class SortRule ( UnaryOpBaseRule ): \"\"\" Sort the input dataframe by the given columns, either ascending or descending. Args: sort_by: Either a single column speified as a string or a list or tuple of columns to sort by ascending: Whether to sort ascending or descending. Boolean. Default: True named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Note: When multiple columns are specified, the first column decides the sort order. For any rows that have the same value in the first column, the second column is used to decide the sort order within that group and so on. \"\"\" def __init__ ( self , sort_by : Iterable [ str ], ascending : Union [ bool , Iterable [ bool ]] = True , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . sort_by = [ col for col in sort_by ] if isinstance ( self . sort_by , str ): self . sort_by = [ self . sort_by ] assert isinstance ( ascending , bool ) or ( isinstance ( ascending , ( list , tuple )) and all ( isinstance ( val , bool ) for val in ascending ) and len ( ascending ) == len ( self . sort_by )), \"ascending must be a bool or a list of bool of the same len as sort_by\" self . ascending = ascending def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) df = df . sort_values ( by = self . sort_by , ascending = self . ascending , ignore_index = True ) self . _set_output_df ( data , df ) concat \u00b6 HConcatRule ( BinaryOpBaseRule ) \u00b6 Horizontally concatenates two dataframe with the result having the columns from the left dataframe followed by the columns from the right dataframe. The columns from the left dataframe will be followed by the columns from the right dataframe in the result dataframe. The two dataframes must not have columns with the same name. Example:: 1 2 3 4 5 6 7 8 9 10 11 Left dataframe: | A | B | | a | 1 | | b | 2 | | c | 3 | Right dataframe: | C | D | | d | 4 | | e | 5 | | f | 6 | After a concat(left, right), the result will look like:: 1 2 3 4 | A | B | C | D | | a | 1 | d | 4 | | b | 2 | e | 5 | | c | 3 | f | 6 | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ColumnAlreadyExistsError raised if the two dataframes have columns with the same name. SchemaError raised in strict mode only if the two dataframes have different number of rows. Source code in etlrules/backends/pandas/concat.py class HConcatRule ( BinaryOpBaseRule ): \"\"\" Horizontally concatenates two dataframe with the result having the columns from the left dataframe followed by the columns from the right dataframe. The columns from the left dataframe will be followed by the columns from the right dataframe in the result dataframe. The two dataframes must not have columns with the same name. Example:: Left dataframe: | A | B | | a | 1 | | b | 2 | | c | 3 | Right dataframe: | C | D | | d | 4 | | e | 5 | | f | 6 | After a concat(left, right), the result will look like:: | A | B | C | D | | a | 1 | d | 4 | | b | 2 | e | 5 | | c | 3 | f | 6 | Args: named_input_left: Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right: Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ColumnAlreadyExistsError: raised if the two dataframes have columns with the same name. SchemaError: raised in strict mode only if the two dataframes have different number of rows. \"\"\" def __init__ ( self , named_input_left : Optional [ str ], named_input_right : Optional [ str ], subset_columns : Optional [ Iterable [ str ]] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): # This __init__ not really needed but the type annotations are extracted from it super () . __init__ ( named_input_left = named_input_left , named_input_right = named_input_right , named_output = named_output , name = name , description = description , strict = strict ) def apply ( self , data ): super () . apply ( data ) left_df = self . _get_input_df_left ( data ) right_df = self . _get_input_df_right ( data ) overlapping_names = set ( left_df . columns ) & set ( right_df . columns ) if overlapping_names : raise ColumnAlreadyExistsError ( f \"Column(s) { overlapping_names } exist in both dataframes.\" ) if self . strict : if len ( left_df ) != len ( right_df ): raise SchemaError ( f \"HConcat needs the two dataframe to have the same number of rows. left df= { len ( left_df ) } rows, right df= { len ( right_df ) } rows.\" ) df = concat ([ left_df , right_df ], axis = 1 ) self . _set_output_df ( data , df ) VConcatRule ( BinaryOpBaseRule ) \u00b6 Vertically concatenates two dataframe with the result having the rows from the left dataframe followed by the rows from the right dataframe. The rows of the right dataframe are added at the bottom of the rows from the left dataframe in the result dataframe. Example:: 1 2 3 4 5 6 7 8 9 10 11 Left dataframe: | A | B | | a | 1 | | b | 2 | | c | 3 | Right dataframe: | A | B | | d | 4 | | e | 5 | | f | 6 | After a concat(left, right), the result will look like:: 1 2 3 4 5 6 7 | A | B | | a | 1 | | b | 2 | | c | 3 | | d | 4 | | e | 5 | | f | 6 | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required subset_columns Optional[Iterable[str]] A subset list of columns available in both dataframes. Only these columns will be concated. The effect is similar to doing a ProjectRule(subset_columns) on both dataframes before the concat. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised if any subset columns specified are missing from any of the dataframe. SchemaError raised in strict mode only if the columns differ between the two dataframes and subset_columns is not specified. Note In strict mode, as described above, SchemaError is raised if the columns are not the same (names, types can be inferred). In non-strict mode, columns are not checked and values are filled with NA when missing. Source code in etlrules/backends/pandas/concat.py class VConcatRule ( BinaryOpBaseRule ): \"\"\" Vertically concatenates two dataframe with the result having the rows from the left dataframe followed by the rows from the right dataframe. The rows of the right dataframe are added at the bottom of the rows from the left dataframe in the result dataframe. Example:: Left dataframe: | A | B | | a | 1 | | b | 2 | | c | 3 | Right dataframe: | A | B | | d | 4 | | e | 5 | | f | 6 | After a concat(left, right), the result will look like:: | A | B | | a | 1 | | b | 2 | | c | 3 | | d | 4 | | e | 5 | | f | 6 | Args: named_input_left: Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right: Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. subset_columns: A subset list of columns available in both dataframes. Only these columns will be concated. The effect is similar to doing a ProjectRule(subset_columns) on both dataframes before the concat. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any subset columns specified are missing from any of the dataframe. SchemaError: raised in strict mode only if the columns differ between the two dataframes and subset_columns is not specified. Note: In strict mode, as described above, SchemaError is raised if the columns are not the same (names, types can be inferred). In non-strict mode, columns are not checked and values are filled with NA when missing. \"\"\" def __init__ ( self , named_input_left : Optional [ str ], named_input_right : Optional [ str ], subset_columns : Optional [ Iterable [ str ]] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input_left = named_input_left , named_input_right = named_input_right , named_output = named_output , name = name , description = description , strict = strict ) self . subset_columns = [ col for col in subset_columns ] if subset_columns is not None else None def apply ( self , data ): super () . apply ( data ) left_df = self . _get_input_df_left ( data ) right_df = self . _get_input_df_right ( data ) if self . subset_columns : if not set ( self . subset_columns ) <= set ( left_df . columns ): raise MissingColumnError ( f \"Missing columns in the left dataframe of the concat operation: { set ( self . subset_columns ) - set ( left_df . columns ) } \" ) if not set ( self . subset_columns ) <= set ( right_df . columns ): raise MissingColumnError ( f \"Missing columns in the right dataframe of the concat operation: { set ( self . subset_columns ) - set ( right_df . columns ) } \" ) left_df = left_df [ self . subset_columns ] right_df = right_df [ self . subset_columns ] if self . strict : if set ( left_df . columns ) != set ( right_df . columns ): raise SchemaError ( f \"VConcat needs both dataframe have the same schema. Missing columns in the right df: { set ( right_df . columns ) - set ( left_df . columns ) } . Missing columns in the left df: { set ( left_df . columns ) - set ( right_df . columns ) } \" ) df = concat ([ left_df , right_df ], axis = 0 , ignore_index = True ) self . _set_output_df ( data , df ) conditions \u00b6 FilterRule ( UnaryOpBaseRule ) \u00b6 Exclude rows based on a condition. Example:: 1 2 3 4 5 6 7 8 Given df: | A | B | | 1 | 2 | | 5 | 3 | | 3 | 4 | rule = FilterRule(\"df['A'] > df['B']\") rule.apply(df) Result:: 1 2 | A | B | | 5 | 3 | Same example using discarded_matching_rows=True:: 1 2 rule = FilterRule(\"df['A'] > df['B']\", discard_matching_rows=True) rule.apply(df) Result:: 1 2 3 | A | B | | 1 | 2 | | 3 | 4 | Parameters: Name Type Description Default condition_expression str An expression as a string. The expression must evaluate to a boolean scalar or a boolean series. required discard_matching_rows bool By default the rows matching the condition (ie where the condition is True) are kept, the rest of the rows being dropped from the result. Setting this parameter to True essentially inverts the condition, so the rows matching the condition are discarded and the rest of the rows kept. Default: False. False named_output_discarded Optional[str] A named output for the records being discarded if those need to be kept for further processing. Default: None, which doesn't keep track of discarded records. None output_column The column name of the result column which will be added to the dataframe. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ExpressionSyntaxError raised if the column expression has a Python syntax error. TypeError raised if an operation is not supported between the types involved NameError raised if an unknown variable is used KeyError raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) Source code in etlrules/backends/pandas/conditions.py class FilterRule ( UnaryOpBaseRule ): \"\"\" Exclude rows based on a condition. Example:: Given df: | A | B | | 1 | 2 | | 5 | 3 | | 3 | 4 | rule = FilterRule(\"df['A'] > df['B']\") rule.apply(df) Result:: | A | B | | 5 | 3 | Same example using discarded_matching_rows=True:: rule = FilterRule(\"df['A'] > df['B']\", discard_matching_rows=True) rule.apply(df) Result:: | A | B | | 1 | 2 | | 3 | 4 | Args: condition_expression: An expression as a string. The expression must evaluate to a boolean scalar or a boolean series. discard_matching_rows: By default the rows matching the condition (ie where the condition is True) are kept, the rest of the rows being dropped from the result. Setting this parameter to True essentially inverts the condition, so the rows matching the condition are discarded and the rest of the rows kept. Default: False. named_output_discarded: A named output for the records being discarded if those need to be kept for further processing. Default: None, which doesn't keep track of discarded records. output_column: The column name of the result column which will be added to the dataframe. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ExpressionSyntaxError: raised if the column expression has a Python syntax error. TypeError: raised if an operation is not supported between the types involved NameError: raised if an unknown variable is used KeyError: raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) \"\"\" EXCLUDE_FROM_COMPARE = ( '_condition_expression' , ) def __init__ ( self , condition_expression : str , discard_matching_rows : bool = False , named_output_discarded : Optional [ str ] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert condition_expression , \"condition_expression cannot be empty\" self . condition_expression = condition_expression self . discard_matching_rows = discard_matching_rows self . named_output_discarded = named_output_discarded self . _condition_expression = Expression ( self . condition_expression , filename = \"FilterRule.py\" ) def apply ( self , data ): df = self . _get_input_df ( data ) cond_series = self . _condition_expression . eval ( df ) if self . discard_matching_rows : cond_series = ~ cond_series self . _set_output_df ( data , df [ cond_series ] . reset_index ( drop = True )) if self . named_output_discarded : data . set_named_output ( self . named_output_discarded , df [ ~ cond_series ] . reset_index ( drop = True )) IfThenElseRule ( UnaryOpBaseRule ) \u00b6 Calculates the ouput based on a condition (If Cond is true Then use then_value Else use else_value). Example:: 1 2 3 4 5 6 7 8 Given df: | A | B | | 1 | 2 | | 5 | 3 | | 3 | 4 | rule = IfThenElseRule(\"df['A'] > df['B']\", output_column=\"C\", then_value=\"A is greater\", else_value=\"B is greater\") rule.apply(df) Result:: 1 2 3 4 | A | B | C | | 1 | 2 | B is greater | | 5 | 3 | A is greater | | 3 | 4 | B is greater | Parameters: Name Type Description Default condition_expression str An expression as a string. The expression must evaluate to a boolean scalar or a boolean series. required then_value Union[int, float, bool, str] The value to use if the condition is true. None then_column Optional[str] Use the value from the then_column if the condition is true. One and only one of then_value and then_column can be used. None else_value Union[int, float, bool, str] The value to use if the condition is false. None else_column Optional[str] Use the value from the else_column if the condition is false. One and only one of the else_value and else_column can be used. None output_column str The column name of the result column which will be added to the dataframe. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ColumnAlreadyExistsError raised in strict mode only if a column with the same name already exists in the dataframe. ExpressionSyntaxError raised if the column expression has a Python syntax error. MissingColumnError raised when then_column or else_column are used but they are missing from the input dataframe. TypeError raised if an operation is not supported between the types involved NameError raised if an unknown variable is used KeyError raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) Source code in etlrules/backends/pandas/conditions.py class IfThenElseRule ( UnaryOpBaseRule ): \"\"\" Calculates the ouput based on a condition (If Cond is true Then use then_value Else use else_value). Example:: Given df: | A | B | | 1 | 2 | | 5 | 3 | | 3 | 4 | rule = IfThenElseRule(\"df['A'] > df['B']\", output_column=\"C\", then_value=\"A is greater\", else_value=\"B is greater\") rule.apply(df) Result:: | A | B | C | | 1 | 2 | B is greater | | 5 | 3 | A is greater | | 3 | 4 | B is greater | Args: condition_expression: An expression as a string. The expression must evaluate to a boolean scalar or a boolean series. then_value: The value to use if the condition is true. then_column: Use the value from the then_column if the condition is true. One and only one of then_value and then_column can be used. else_value: The value to use if the condition is false. else_column: Use the value from the else_column if the condition is false. One and only one of the else_value and else_column can be used. output_column: The column name of the result column which will be added to the dataframe. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ColumnAlreadyExistsError: raised in strict mode only if a column with the same name already exists in the dataframe. ExpressionSyntaxError: raised if the column expression has a Python syntax error. MissingColumnError: raised when then_column or else_column are used but they are missing from the input dataframe. TypeError: raised if an operation is not supported between the types involved NameError: raised if an unknown variable is used KeyError: raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) \"\"\" EXCLUDE_FROM_COMPARE = ( '_condition_expression' , ) def __init__ ( self , condition_expression : str , output_column : str , then_value : Optional [ Union [ int , float , bool , str ]] = None , then_column : Optional [ str ] = None , else_value : Optional [ Union [ int , float , bool , str ]] = None , else_column : Optional [ str ] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert bool ( then_value is None ) != bool ( then_column is None ), \"One and only one of then_value and then_column can be specified.\" assert bool ( else_value is None ) != bool ( else_column is None ), \"One and only one of else_value and else_column can be specified.\" assert condition_expression , \"condition_expression cannot be empty\" assert output_column , \"output_column cannot be empty\" self . condition_expression = condition_expression self . output_column = output_column self . then_value = then_value self . then_column = then_column self . else_value = else_value self . else_column = else_column self . _condition_expression = Expression ( self . condition_expression , filename = f ' { self . output_column } .py' ) def apply ( self , data ): df = self . _get_input_df ( data ) df_columns = set ( df . columns ) if self . strict and self . output_column in df_columns : raise ColumnAlreadyExistsError ( f \"Column { self . output_column } already exists in the input dataframe.\" ) if self . then_column is not None and self . then_column not in df_columns : raise MissingColumnError ( f \"Column { self . then_column } is missing from the input dataframe.\" ) if self . else_column is not None and self . else_column not in df_columns : raise MissingColumnError ( f \"Column { self . else_column } is missing from the input dataframe.\" ) cond_series = self . _condition_expression . eval ( df ) then_value = self . then_value if self . then_value is not None else df [ self . then_column ] else_value = self . else_value if self . else_value is not None else df [ self . else_column ] result = np . where ( cond_series , then_value , else_value ) df = df . assign ( ** { self . output_column : result }) self . _set_output_df ( data , df ) fill \u00b6 BackFillRule ( BaseFillRule ) \u00b6 Replaces NAs/missing values with the next non-NA value, optionally sorting and grouping the data. Example:: 1 2 3 4 | A | B | | a | NA | | b | 2 | | a | NA | After a fill forward:: 1 2 3 4 | A | B | | a | 2 | | b | 2 | | a | NA | After a fill forward with group_by=[\"A\"]:: 1 2 3 4 | A | B | | a | NA | | b | 2 | | a | NA | The \"a\" group has no non-NA value, so it is not filled. The \"b\" group has a non-NA value of 2 but not other NA values, so nothing to fill. Parameters: Name Type Description Default columns Iterable[str] The list of columns to replaces NAs for. The rest of the columns in the dataframe are not affected. required sort_by Optional[Iterable[str]] The list of columns to sort by before the fill operation. Optional. Given the previous non-NA values are used, sorting can make a difference in the values uses. required sort_ascending bool When sort_by is specified, True means sort ascending, False sort descending. required group_by Optional[Iterable[str]] The list of columns to group by before the fill operation. Optional. The fill values are only used within a group, other adjacent groups are not filled. Useful when you want to copy(fill) data at a certain group level. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns specified in either columns, sort_by or group_by are missing from the dataframe. Source code in etlrules/backends/pandas/fill.py class BackFillRule ( BaseFillRule ): \"\"\" Replaces NAs/missing values with the next non-NA value, optionally sorting and grouping the data. Example:: | A | B | | a | NA | | b | 2 | | a | NA | After a fill forward:: | A | B | | a | 2 | | b | 2 | | a | NA | After a fill forward with group_by=[\"A\"]:: | A | B | | a | NA | | b | 2 | | a | NA | The \"a\" group has no non-NA value, so it is not filled. The \"b\" group has a non-NA value of 2 but not other NA values, so nothing to fill. Args: columns (Iterable[str]): The list of columns to replaces NAs for. The rest of the columns in the dataframe are not affected. sort_by (Optional[Iterable[str]]): The list of columns to sort by before the fill operation. Optional. Given the previous non-NA values are used, sorting can make a difference in the values uses. sort_ascending (bool): When sort_by is specified, True means sort ascending, False sort descending. group_by (Optional[Iterable[str]]): The list of columns to group by before the fill operation. Optional. The fill values are only used within a group, other adjacent groups are not filled. Useful when you want to copy(fill) data at a certain group level. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns specified in either columns, sort_by or group_by are missing from the dataframe. \"\"\" FILL_METHOD = \"bfill\" ForwardFillRule ( BaseFillRule ) \u00b6 Replaces NAs/missing values with the next non-NA value, optionally sorting and grouping the data. Example:: 1 2 3 4 | A | B | | a | 1 | | b | NA | | a | NA | After a fill forward:: 1 2 3 4 | A | B | | a | 1 | | b | 1 | | a | 1 | After a fill forward with group_by=[\"A\"]:: 1 2 3 4 | A | B | | a | 1 | | b | NA | | a | 1 | The \"a\" group has the first non-NA value as 1 and that is used \"forward\" to fill the 3rd row. The \"b\" group has no non-NA values, so nothing to fill. Parameters: Name Type Description Default columns Iterable[str] The list of columns to replaces NAs for. The rest of the columns in the dataframe are not affected. required sort_by Optional[Iterable[str]] The list of columns to sort by before the fill operation. Optional. Given the previous non-NA values are used, sorting can make a difference in the values uses. required sort_ascending bool When sort_by is specified, True means sort ascending, False sort descending. required group_by Optional[Iterable[str]] The list of columns to group by before the fill operation. Optional. The fill values are only used within a group, other adjacent groups are not filled. Useful when you want to copy(fill) data at a certain group level. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns specified in either columns, sort_by or group_by are missing from the dataframe. Source code in etlrules/backends/pandas/fill.py class ForwardFillRule ( BaseFillRule ): \"\"\" Replaces NAs/missing values with the next non-NA value, optionally sorting and grouping the data. Example:: | A | B | | a | 1 | | b | NA | | a | NA | After a fill forward:: | A | B | | a | 1 | | b | 1 | | a | 1 | After a fill forward with group_by=[\"A\"]:: | A | B | | a | 1 | | b | NA | | a | 1 | The \"a\" group has the first non-NA value as 1 and that is used \"forward\" to fill the 3rd row. The \"b\" group has no non-NA values, so nothing to fill. Args: columns (Iterable[str]): The list of columns to replaces NAs for. The rest of the columns in the dataframe are not affected. sort_by (Optional[Iterable[str]]): The list of columns to sort by before the fill operation. Optional. Given the previous non-NA values are used, sorting can make a difference in the values uses. sort_ascending (bool): When sort_by is specified, True means sort ascending, False sort descending. group_by (Optional[Iterable[str]]): The list of columns to group by before the fill operation. Optional. The fill values are only used within a group, other adjacent groups are not filled. Useful when you want to copy(fill) data at a certain group level. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description Optional[str]: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns specified in either columns, sort_by or group_by are missing from the dataframe. \"\"\" FILL_METHOD = \"ffill\" joins \u00b6 InnerJoinRule ( BaseJoinRule ) \u00b6 Performs a database-style inner join operation on two data frames. A join involves two data frames left_df right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. An inner join specifies that only those rows that have key values in both left and right will be copied over and merged into the result data frame. Any rows without corresponding values on the other side (be it left or right) will be dropped from the result. Examples: left dataframe:: 1 2 3 | A | B | | 1 | a | | 2 | b | right dataframe:: 1 2 3 | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: 1 2 | A | B | C | | 1 | a | c | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required key_columns_left Iterable[str] A list or tuple of column names to join on (columns in the left data frame) required key_columns_right Optional[Iterable[str]] A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. required suffixes Iterable[Optional[str]] A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns (keys) are missing from any of the two input data frames. Source code in etlrules/backends/pandas/joins.py class InnerJoinRule ( BaseJoinRule ): \"\"\" Performs a database-style inner join operation on two data frames. A join involves two data frames left_df <join> right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. An inner join specifies that only those rows that have key values in both left and right will be copied over and merged into the result data frame. Any rows without corresponding values on the other side (be it left or right) will be dropped from the result. Example: left dataframe:: | A | B | | 1 | a | | 2 | b | right dataframe:: | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: | A | B | C | | 1 | a | c | Args: named_input_left (Optional[str]): Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right (Optional[str]): Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. key_columns_left (Iterable[str]): A list or tuple of column names to join on (columns in the left data frame) key_columns_right (Optional[Iterable[str]]): A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. suffixes (Iterable[Optional[str]]): A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns (keys) are missing from any of the two input data frames. \"\"\" JOIN_TYPE = \"inner\" LeftJoinRule ( BaseJoinRule ) \u00b6 Performs a database-style left join operation on two data frames. A join involves two data frames left_df right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. A left join specifies that all the rows in the left dataframe will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the right dataframe. The right columns will be populated with NaNs/None when there is no corresponding row on the right. Examples: left dataframe:: 1 2 3 | A | B | | 1 | a | | 2 | b | right dataframe:: 1 2 3 | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: 1 2 3 | A | B | C | | 1 | a | c | | 2 | b | NA | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required key_columns_left Iterable[str] A list or tuple of column names to join on (columns in the left data frame) required key_columns_right Optional[Iterable[str]] A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. required suffixes Iterable[Optional[str]] A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns (keys) are missing from any of the two input data frames. Source code in etlrules/backends/pandas/joins.py class LeftJoinRule ( BaseJoinRule ): \"\"\" Performs a database-style left join operation on two data frames. A join involves two data frames left_df <join> right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. A left join specifies that all the rows in the left dataframe will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the right dataframe. The right columns will be populated with NaNs/None when there is no corresponding row on the right. Example: left dataframe:: | A | B | | 1 | a | | 2 | b | right dataframe:: | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: | A | B | C | | 1 | a | c | | 2 | b | NA | Args: named_input_left (Optional[str]): Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right (Optional[str]): Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. key_columns_left (Iterable[str]): A list or tuple of column names to join on (columns in the left data frame) key_columns_right (Optional[Iterable[str]]): A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. suffixes (Iterable[Optional[str]]): A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns (keys) are missing from any of the two input data frames. \"\"\" JOIN_TYPE = \"left\" OuterJoinRule ( BaseJoinRule ) \u00b6 Performs a database-style left join operation on two data frames. A join involves two data frames left_df right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. An outer join specifies that all the rows in the both left and right dataframes will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the other dataframe. The missing side will have its columns populated with NA when the rows are missing. Examples: left dataframe:: 1 2 3 | A | B | | 1 | a | | 2 | b | right dataframe:: 1 2 3 | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: 1 2 3 4 | A | B | C | | 1 | a | c | | 2 | b | NA | | 3 | NA | d | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required key_columns_left Iterable[str] A list or tuple of column names to join on (columns in the left data frame) required key_columns_right Optional[Iterable[str]] A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. required suffixes Iterable[Optional[str]] A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns (keys) are missing from any of the two input data frames. Source code in etlrules/backends/pandas/joins.py class OuterJoinRule ( BaseJoinRule ): \"\"\" Performs a database-style left join operation on two data frames. A join involves two data frames left_df <join> right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. An outer join specifies that all the rows in the both left and right dataframes will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the other dataframe. The missing side will have its columns populated with NA when the rows are missing. Example: left dataframe:: | A | B | | 1 | a | | 2 | b | right dataframe:: | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: | A | B | C | | 1 | a | c | | 2 | b | NA | | 3 | NA | d | Args: named_input_left (Optional[str]): Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right (Optional[str]): Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. key_columns_left (Iterable[str]): A list or tuple of column names to join on (columns in the left data frame) key_columns_right (Optional[Iterable[str]]): A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. suffixes (Iterable[Optional[str]]): A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns (keys) are missing from any of the two input data frames. \"\"\" JOIN_TYPE = \"outer\" RightJoinRule ( BaseJoinRule ) \u00b6 Performs a database-style left join operation on two data frames. A join involves two data frames left_df right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. A right join specifies that all the rows in the right dataframe will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the left dataframe. The left columns will be populated with NA when there is no corresponding row on the left. Examples: left dataframe:: 1 2 3 | A | B | | 1 | a | | 2 | b | right dataframe:: 1 2 3 | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: 1 2 3 | A | B | C | | 1 | a | c | | 3 | NA | d | Note A right join is equivalent to a left join with the dataframes inverted, ie: left_df right_df is equivalent to right_df left_df although the order of the rows will be different. Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required key_columns_left Iterable[str] A list or tuple of column names to join on (columns in the left data frame) required key_columns_right Optional[Iterable[str]] A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. required suffixes Iterable[Optional[str]] A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns (keys) are missing from any of the two input data frames. Source code in etlrules/backends/pandas/joins.py class RightJoinRule ( BaseJoinRule ): \"\"\" Performs a database-style left join operation on two data frames. A join involves two data frames left_df <join> right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. A right join specifies that all the rows in the right dataframe will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the left dataframe. The left columns will be populated with NA when there is no corresponding row on the left. Example: left dataframe:: | A | B | | 1 | a | | 2 | b | right dataframe:: | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: | A | B | C | | 1 | a | c | | 3 | NA | d | Note: A right join is equivalent to a left join with the dataframes inverted, ie: left_df <left_join> right_df is equivalent to right_df <right_join> left_df although the order of the rows will be different. Args: named_input_left (Optional[str]): Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right (Optional[str]): Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. key_columns_left (Iterable[str]): A list or tuple of column names to join on (columns in the left data frame) key_columns_right (Optional[Iterable[str]]): A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. suffixes (Iterable[Optional[str]]): A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns (keys) are missing from any of the two input data frames. \"\"\" JOIN_TYPE = \"right\" newcolumns \u00b6 AddNewColumnRule ( UnaryOpBaseRule ) \u00b6 Adds a new column and sets it to the value of an evaluated expression. Example:: 1 2 3 4 5 Given df: | A | B | | 1 | 2 | | 2 | 3 | | 3 | 4 | AddNewColumnRule(\"Sum\", \"df['A'] + df['B']\").apply(df) Result:: 1 2 3 4 | A | B | Sum | | 1 | 2 | 3 | | 2 | 3 | 5 | | 3 | 4 | 7 | Parameters: Name Type Description Default column_name str The name of the new column to be added. required column_expression str An expression that gets evaluated and produces the value for the new column. The syntax: df[\"EXISTING_COL\"] can be used in the expression to refer to other columns in the dataframe. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ColumnAlreadyExistsError raised in strict mode only if a column with the same name already exists in the dataframe. ExpressionSyntaxError raised if the column expression has a Python syntax error. TypeError raised if an operation is not supported between the types involved NameError raised if an unknown variable is used KeyError raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) Note The implementation will try to use dataframe operations for performance, but when those are not supported it will fallback to row level operations. Note NA are treated slightly differently between dataframe level operations and row level. At dataframe level operations, NAs in operations will make the result be NA. In row level operations, NAs will generally raise a TypeError. To avoid such behavior, fill the NAs before performing operations. Source code in etlrules/backends/pandas/newcolumns.py class AddNewColumnRule ( UnaryOpBaseRule ): \"\"\" Adds a new column and sets it to the value of an evaluated expression. Example:: Given df: | A | B | | 1 | 2 | | 2 | 3 | | 3 | 4 | > AddNewColumnRule(\"Sum\", \"df['A'] + df['B']\").apply(df) Result:: | A | B | Sum | | 1 | 2 | 3 | | 2 | 3 | 5 | | 3 | 4 | 7 | Args: column_name: The name of the new column to be added. column_expression: An expression that gets evaluated and produces the value for the new column. The syntax: df[\"EXISTING_COL\"] can be used in the expression to refer to other columns in the dataframe. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ColumnAlreadyExistsError: raised in strict mode only if a column with the same name already exists in the dataframe. ExpressionSyntaxError: raised if the column expression has a Python syntax error. TypeError: raised if an operation is not supported between the types involved NameError: raised if an unknown variable is used KeyError: raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) Note: The implementation will try to use dataframe operations for performance, but when those are not supported it will fallback to row level operations. Note: NA are treated slightly differently between dataframe level operations and row level. At dataframe level operations, NAs in operations will make the result be NA. In row level operations, NAs will generally raise a TypeError. To avoid such behavior, fill the NAs before performing operations. \"\"\" EXCLUDE_FROM_COMPARE = ( '_column_expression' , ) def __init__ ( self , column_name : str , column_expression : str , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . column_name = column_name self . column_expression = column_expression self . _column_expression = Expression ( self . column_expression , filename = f ' { self . column_name } _expression.py' ) def apply ( self , data ): df = self . _get_input_df ( data ) if self . strict and self . column_name in df . columns : raise ColumnAlreadyExistsError ( f \"Column { self . column_name } already exists in the input dataframe.\" ) result = self . _column_expression . eval ( df ) df = df . assign ( ** { self . column_name : result }) self . _set_output_df ( data , df ) numeric \u00b6 AbsRule ( UnaryOpBaseRule , ColumnsInOutMixin ) \u00b6 Converts numbers to absolute values. Basic usage:: 1 2 rule = AbsRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of numeric columns to convert to absolute values. required output_columns Optional[Iterable[str]] A list of new names for the columns with the absolute values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the absolute values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/numeric.py class AbsRule ( UnaryOpBaseRule , ColumnsInOutMixin ): \"\"\" Converts numbers to absolute values. Basic usage:: rule = AbsRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Args: columns: A list of numeric columns to convert to absolute values. output_columns: A list of new names for the columns with the absolute values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the absolute values. If not provided, the result is updated in place. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , columns : Iterable [ str ], output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . columns = [ col for col in columns ] self . output_columns = [ out_col for out_col in output_columns ] if output_columns else None def apply ( self , data ): df = self . _get_input_df ( data ) columns , output_columns = self . validate_columns_in_out ( df , self . columns , self . output_columns , self . strict ) abs_df = df [ columns ] . abs () df = df . assign ( ** { output_col : abs_df [ col ] for col , output_col in zip ( columns , output_columns )}) self . _set_output_df ( data , df ) RoundRule ( UnaryOpBaseRule ) \u00b6 Rounds a set of columns to specified decimal places. Basic usage:: 1 2 3 # rounds Col_A to 2dps, Col_B to 0dps and Col_C to 4dps rule = RoundRule({\"Col_A\": 2, \"Col_B\": 0, \"Col_C\": 4}) rule.apply(data) Parameters: Name Type Description Default mapper Mapping[str, int] A dict {column_name: scale} which specifies to round each column to the number of decimal places specified in the scale. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column in the mapper doesn't exist in the input dataframe. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/numeric.py class RoundRule ( UnaryOpBaseRule ): \"\"\" Rounds a set of columns to specified decimal places. Basic usage:: # rounds Col_A to 2dps, Col_B to 0dps and Col_C to 4dps rule = RoundRule({\"Col_A\": 2, \"Col_B\": 0, \"Col_C\": 4}) rule.apply(data) Args: mapper: A dict {column_name: scale} which specifies to round each column to the number of decimal places specified in the scale. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column in the mapper doesn't exist in the input dataframe. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , mapper : Mapping [ str , int ], named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert all ( isinstance ( col , str ) and isinstance ( scale , ( int , float )) and int ( scale ) >= 0 for col , scale in mapper . items ()), \"Mapper is a {column_name: precision} where column names are strings and precision is an int or float and >=0.\" self . mapper = { col : int ( scale ) for col , scale in mapper . items ()} def apply ( self , data ): df = self . _get_input_df ( data ) if self . strict : if not set ( self . mapper . keys ()) <= set ( df . columns ): raise MissingColumnError ( f \"Column(s) { set ( self . mapper . keys ()) - set ( df . columns ) } are missing from the input dataframe.\" ) mapper = self . mapper else : mapper = { col : scale for col , scale in self . mapper . items () if col in df . columns } df = df . round ( mapper ) self . _set_output_df ( data , df ) strings \u00b6 StrCapitalizeRule ( BaseAssignRule ) \u00b6 Converts a set of string columns to capitalize. Capitalization will convert the first letter in the string to upper case and the rest of the letters to lower case. Basic usage:: 1 2 rule = StrCapitalizeRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to capitalize. required output_columns Optional[Iterable[str]] A list of new names for the columns with the capitalized values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the capitalized values. If not provided, the result is updated in place. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrCapitalizeRule ( BaseAssignRule ): \"\"\" Converts a set of string columns to capitalize. Capitalization will convert the first letter in the string to upper case and the rest of the letters to lower case. Basic usage:: rule = StrCapitalizeRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to capitalize. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the capitalized values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the capitalized values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def do_apply ( self , col ): return col . str . capitalize () StrExtractRule ( UnaryOpBaseRule , ColumnsInOutMixin ) \u00b6 Extract substrings from strings columns using regular expressions. Basic usage:: 1 2 3 4 5 6 7 8 9 # extracts the number between start_ and _end # ie: for an input value of start_1234_end - will extract 1234 in col_A rule = StrExtractRule([\"col_A\"], regular_expression=r\"start_([\\d]*)_end\") rule.apply(data) # extracts with multiple groups, extracting the single digit at the end as well # for an input value of start_1234_end_9, col_1 will extract 1234, col_2 will extract 9 rule = StrExtractRule([\"col_A\"], regular_expression=r\"start_([\\d]*)_end_([\\d])\", output_columns=[\"col_1\", \"col_2\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required regular_expression str The regular expression used to extract data. The regular expression must have 1 or more groups - ie sections between brackets. The groups do the actual extraction of data. If there is a single group, then the column can be modified in place (ie no output_columns are needed) but if there are multiple groups, then output_columns must be specified as each group will be extracted in a new output column. required keep_original_value bool Only used in case there isn't a match and it specifies if NA should be used in the output or the original value. Defaults: True. If the regular expression has multiple groups and therefore multiple output_columns, only the first output column will keep the original value, the rest will be populated with NA. False output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, it must have one output_column per regular expression group, for every input columns. For example, if input column is [\"A\"] and the regular expression is \"a_([\\d]) ([\\d])\" with 2 groups, then the output columns must have 2 columns (one per group) - for example [\"A1_out\", \"A2_out\"]. If the input columns are [\"A\", \"B\"] and the regular expression is \"a ([\\d])_([\\d])\" with 2 groups, then the output columns must have 2 columns (one per group) for every input column - e.g. [\"A1_out\", \"A2_out\", \"B1_out\", \"B2_out\"]. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place (only possible if the regular expression has a single group). None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrExtractRule ( UnaryOpBaseRule , ColumnsInOutMixin ): r \"\"\" Extract substrings from strings columns using regular expressions. Basic usage:: # extracts the number between start_ and _end # ie: for an input value of start_1234_end - will extract 1234 in col_A rule = StrExtractRule([\"col_A\"], regular_expression=r\"start_([\\d]*)_end\") rule.apply(data) # extracts with multiple groups, extracting the single digit at the end as well # for an input value of start_1234_end_9, col_1 will extract 1234, col_2 will extract 9 rule = StrExtractRule([\"col_A\"], regular_expression=r\"start_([\\d]*)_end_([\\d])\", output_columns=[\"col_1\", \"col_2\"]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. regular_expression: The regular expression used to extract data. The regular expression must have 1 or more groups - ie sections between brackets. The groups do the actual extraction of data. If there is a single group, then the column can be modified in place (ie no output_columns are needed) but if there are multiple groups, then output_columns must be specified as each group will be extracted in a new output column. keep_original_value: Only used in case there isn't a match and it specifies if NA should be used in the output or the original value. Defaults: True. If the regular expression has multiple groups and therefore multiple output_columns, only the first output column will keep the original value, the rest will be populated with NA. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, it must have one output_column per regular expression group, for every input columns. For example, if input column is [\"A\"] and the regular expression is \"a_([\\d])_([\\d])\" with 2 groups, then the output columns must have 2 columns (one per group) - for example [\"A1_out\", \"A2_out\"]. If the input columns are [\"A\", \"B\"] and the regular expression is \"a_([\\d])_([\\d])\" with 2 groups, then the output columns must have 2 columns (one per group) for every input column - e.g. [\"A1_out\", \"A2_out\", \"B1_out\", \"B2_out\"]. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place (only possible if the regular expression has a single group). named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , columns : Iterable [ str ], regular_expression : str , keep_original_value : bool = False , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . columns = [ col for col in columns ] self . output_columns = [ out_col for out_col in output_columns ] if output_columns else None self . regular_expression = regular_expression self . _compiled_expr = re . compile ( regular_expression ) groups = self . _compiled_expr . groups assert groups > 0 , \"The regular expression must have at least 1 group - ie a secstion in () - which gets extracted.\" if groups == 1 and self . output_columns is not None : assert len ( self . output_columns ) == len ( self . columns ), \"The regular expression has one group and the output_columns must match 1 to 1 the length of the columns\" if groups > 1 : assert self . output_columns is not None , f \"The regular expression has { groups } groups in which case the output_columns must be specified.\" assert len ( self . output_columns ) == groups * len ( self . columns ), f \"The regular expression has { groups } groups, the output_columns must have { groups } columns per each input column.\" self . keep_original_value = keep_original_value def apply ( self , data ): df = self . _get_input_df ( data ) columns , output_columns = self . validate_columns_in_out ( df , self . columns , self . output_columns , self . strict , validate_length = False ) new_cols_dict = {} groups = self . _compiled_expr . groups for idx , col in enumerate ( columns ): new_col = df [ col ] . str . extract ( self . _compiled_expr , expand = True ) if self . keep_original_value : # only the first new column keeps the value (in case of multiple groups) new_col [ 0 ] . fillna ( value = df [ col ], inplace = True ) for group in range ( groups ): new_cols_dict [ output_columns [ idx * groups + group ]] = new_col [ group ] df = df . assign ( ** new_cols_dict ) self . _set_output_df ( data , df ) StrLowerRule ( BaseAssignRule ) \u00b6 Converts a set of string columns to lower case. Basic usage:: 1 2 rule = StrLowerRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to lower case. required output_columns Optional[Iterable[str]] A list of new names for the columns with the lower case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the lower case values. If not provided, the result is updated in place. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrLowerRule ( BaseAssignRule ): \"\"\" Converts a set of string columns to lower case. Basic usage:: rule = StrLowerRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to lower case. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the lower case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the lower case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def do_apply ( self , col ): return col . str . lower () StrPadRule ( BaseAssignRule ) \u00b6 Makes strings of a given width (justifies) by padding left, right or both sides with a fill character. Basic usage:: 1 2 rule = StrPadRule([\"col_A\", \"col_B\", \"col_C\"], width=8, fill_character=\".\", how=\"right\") rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required width int Pad with the fill_character to this width. required fill_character str Character to fill with. Defaults to whitespace. required how Literal['left', 'right', 'both'] How should the stripping be done. One of left, right, both. Left pads at the beggining of the string, right pads at the end, while both pads at both ends. 'both' output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrPadRule ( BaseAssignRule ): \"\"\" Makes strings of a given width (justifies) by padding left, right or both sides with a fill character. Basic usage:: rule = StrPadRule([\"col_A\", \"col_B\", \"col_C\"], width=8, fill_character=\".\", how=\"right\") rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. width: Pad with the fill_character to this width. fill_character: Character to fill with. Defaults to whitespace. how: How should the stripping be done. One of left, right, both. Left pads at the beggining of the string, right pads at the end, while both pads at both ends. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" PAD_LEFT = 'left' PAD_RIGHT = 'right' PAD_BOTH = 'both' def __init__ ( self , columns : Iterable [ str ], width : int , fill_character : str , how : Literal [ PAD_LEFT , PAD_RIGHT , PAD_BOTH ] = PAD_BOTH , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert how in ( self . PAD_LEFT , self . PAD_RIGHT , self . PAD_BOTH ), f \"Unknown how parameter { how } . It must be one of: { ( self . PAD_LEFT , self . PAD_RIGHT , self . PAD_BOTH ) } \" self . how = how self . width = width self . fill_character = fill_character def do_apply ( self , col ): if self . how == self . PAD_RIGHT : return col . str . ljust ( self . width , fillchar = self . fill_character ) elif self . how == self . PAD_LEFT : return col . str . rjust ( self . width , fillchar = self . fill_character ) return col . str . center ( self . width , fillchar = self . fill_character ) StrSplitRejoinRule ( BaseAssignRule ) \u00b6 Splits a string into an array of substrings based on a string separator or a regular expression, then rejoin with a new separator, optionally sorting the substrings. Note The output is an array of substrings which can optionally be limited via the limit parameter to only include the first number of substrings. Basic usage:: 1 2 3 4 # splits col_A, col_B, col_C on , # \"b,d;a,c\" will be split and rejoined as \"b|c|d;a\" rule = StrSplitRejoinRule([\"col_A\", \"col_B\", \"col_C\"], separator=\",\", new_separator=\"|\", sort=\"ascending\") rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required separator Optional[str] A literal value to split the string by. Optional. None separator_regex Optional[str] A regular expression to split the string by. Optional Note: One and only one of separator or separator_regex must be specified. None limit Optional[int] A limit to the number of substrings. If specified, only the first substrings are returned plus an additional remainder. At most, limit + 1 substrings are returned with the last beind the remainder. None new_separator str A new separator used to rejoin the substrings. ',' sort Optional[Literal['ascending', 'descending']] Optionally sorts the substrings before rejoining using the new_separator. It can be set to either ascending or descending, sorting the substrings accordingly. When the value is set to None, there is no sorting. None output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrSplitRejoinRule ( BaseAssignRule ): \"\"\" Splits a string into an array of substrings based on a string separator or a regular expression, then rejoin with a new separator, optionally sorting the substrings. Note: The output is an array of substrings which can optionally be limited via the limit parameter to only include the first <limit> number of substrings. Basic usage:: # splits col_A, col_B, col_C on , # \"b,d;a,c\" will be split and rejoined as \"b|c|d;a\" rule = StrSplitRejoinRule([\"col_A\", \"col_B\", \"col_C\"], separator=\",\", new_separator=\"|\", sort=\"ascending\") rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. separator: A literal value to split the string by. Optional. separator_regex: A regular expression to split the string by. Optional Note: One and only one of separator or separator_regex must be specified. limit: A limit to the number of substrings. If specified, only the first <limit> substrings are returned plus an additional remainder. At most, limit + 1 substrings are returned with the last beind the remainder. new_separator: A new separator used to rejoin the substrings. sort: Optionally sorts the substrings before rejoining using the new_separator. It can be set to either ascending or descending, sorting the substrings accordingly. When the value is set to None, there is no sorting. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" SORT_ASCENDING = \"ascending\" SORT_DESCENDING = \"descending\" def __init__ ( self , columns : Iterable [ str ], separator : Optional [ str ] = None , separator_regex : Optional [ str ] = None , limit : Optional [ int ] = None , new_separator : str = \",\" , sort : Optional [ Literal [ SORT_ASCENDING , SORT_DESCENDING ]] = None , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert bool ( separator ) != bool ( separator_regex ), \"One and only one of separator and separator_regex can be specified.\" self . separator = separator self . separator_regex = separator_regex self . _compiled_regex = re . compile ( self . separator_regex ) if self . separator_regex is not None else None self . limit = limit assert isinstance ( new_separator , str ) and new_separator self . new_separator = new_separator assert sort in ( None , self . SORT_ASCENDING , self . SORT_DESCENDING ) self . sort = sort def do_apply ( self , col ): if self . separator_regex is not None : new_col = col . str . split ( pat = self . _compiled_regex , n = self . limit , regex = True ) else : new_col = col . str . split ( pat = self . separator , n = self . limit , regex = False ) new_separator = self . new_separator if self . sort is not None : reverse = self . sort == self . SORT_DESCENDING func = lambda val : new_separator . join ( sorted ( val , reverse = reverse )) if val not in ( nan , NA , None ) else val else : func = lambda val : new_separator . join ( val ) if val not in ( nan , NA , None ) else val return new_col . apply ( func ) StrSplitRule ( BaseAssignRule ) \u00b6 Splits a string into an array of substrings based on a string separator or a regular expression. Note The output is an array of substrings which can optionally be limited via the limit parameter to only include the first number of substrings. If you need the output to be a string, perhaps joined on a different separator and optionally sorted then use the StrSplitRejoinRule rule. Basic usage:: 1 2 3 4 5 6 7 8 9 # splits col_A, col_B, col_C on , # \"a,b;c,d\" will be split as [\"a\", \"b;c\", \"d\"] rule = StrSplitRule([\"col_A\", \"col_B\", \"col_C\"], separator=\",\") rule.apply(data) # splits col_A, col_B, col_C on either , or ; # \"a,b;c,d\" will be split as [\"a\", \"b\", \"c\", \"d\"] rule = StrSplitRule([\"col_A\", \"col_B\", \"col_C\"], separator_regex=\",|;\") rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required separator Optional[str] A literal value to split the string by. Optional. None separator_regex Optional[str] A regular expression to split the string by. Optional Note: One and only one of separator or separator_regex must be specified. None limit Optional[int] A limit to the number of substrings. If specified, only the first substrings are returned plus an additional remainder. At most, limit + 1 substrings are returned with the last beind the remainder. None output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrSplitRule ( BaseAssignRule ): \"\"\" Splits a string into an array of substrings based on a string separator or a regular expression. Note: The output is an array of substrings which can optionally be limited via the limit parameter to only include the first <limit> number of substrings. If you need the output to be a string, perhaps joined on a different separator and optionally sorted then use the StrSplitRejoinRule rule. Basic usage:: # splits col_A, col_B, col_C on , # \"a,b;c,d\" will be split as [\"a\", \"b;c\", \"d\"] rule = StrSplitRule([\"col_A\", \"col_B\", \"col_C\"], separator=\",\") rule.apply(data) # splits col_A, col_B, col_C on either , or ; # \"a,b;c,d\" will be split as [\"a\", \"b\", \"c\", \"d\"] rule = StrSplitRule([\"col_A\", \"col_B\", \"col_C\"], separator_regex=\",|;\") rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. separator: A literal value to split the string by. Optional. separator_regex: A regular expression to split the string by. Optional Note: One and only one of separator or separator_regex must be specified. limit: A limit to the number of substrings. If specified, only the first <limit> substrings are returned plus an additional remainder. At most, limit + 1 substrings are returned with the last beind the remainder. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , columns : Iterable [ str ], separator : Optional [ str ] = None , separator_regex : Optional [ str ] = None , limit : Optional [ int ] = None , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert bool ( separator ) != bool ( separator_regex ), \"One and only one of separator and separator_regex can be specified.\" self . separator = separator self . separator_regex = separator_regex self . _compiled_regex = re . compile ( self . separator_regex ) if self . separator_regex is not None else None self . limit = limit def do_apply ( self , col ): if self . separator_regex is not None : return col . str . split ( pat = self . _compiled_regex , n = self . limit , regex = True ) return col . str . split ( pat = self . separator , n = self . limit , regex = False ) StrStripRule ( BaseAssignRule ) \u00b6 Strips leading, trailing or both whitespaces or other characters from given columns. Basic usage:: 1 2 rule = StrStripRule([\"col_A\", \"col_B\", \"col_C\"], how=\"both\") rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required how Literal['left', 'right', 'both'] How should the stripping be done. One of left, right, both. Left strips leading characters, right trailing characters and both at both ends. 'both' characters Optional[str] If set, it contains a list of characters to be stripped. When not specified or when set to None, whitespace is removed. None output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrStripRule ( BaseAssignRule ): \"\"\" Strips leading, trailing or both whitespaces or other characters from given columns. Basic usage:: rule = StrStripRule([\"col_A\", \"col_B\", \"col_C\"], how=\"both\") rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. how: How should the stripping be done. One of left, right, both. Left strips leading characters, right trailing characters and both at both ends. characters: If set, it contains a list of characters to be stripped. When not specified or when set to None, whitespace is removed. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" STRIP_LEFT = 'left' STRIP_RIGHT = 'right' STRIP_BOTH = 'both' def __init__ ( self , columns : Iterable [ str ], how : Literal [ STRIP_LEFT , STRIP_RIGHT , STRIP_BOTH ] = STRIP_BOTH , characters : Optional [ str ] = None , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert how in ( self . STRIP_BOTH , self . STRIP_LEFT , self . STRIP_RIGHT ), f \"Unknown how parameter { how } . It must be one of: { ( self . STRIP_BOTH , self . STRIP_LEFT , self . STRIP_RIGHT ) } \" self . how = how self . characters = characters or None def do_apply ( self , col ): if self . how == self . STRIP_BOTH : return col . str . strip ( to_strip = self . characters ) elif self . how == self . STRIP_RIGHT : return col . str . rstrip ( to_strip = self . characters ) return col . str . lstrip ( to_strip = self . characters ) StrUpperRule ( BaseAssignRule ) \u00b6 Converts a set of string columns to upper case. Basic usage:: 1 2 rule = StrUpperRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrUpperRule ( BaseAssignRule ): \"\"\" Converts a set of string columns to upper case. Basic usage:: rule = StrUpperRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def do_apply ( self , col ): return col . str . upper () types \u00b6 TypeConversionRule ( UnaryOpBaseRule ) \u00b6 Converts the type of a given set of columns to other types. Parameters: Name Type Description Default mapper Mapping[str, str] A dict with columns names as keys and the new types as values. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError is raised when a column specified in the mapper doesn't exist in the input data frame. UnsupportedTypeError is raised when an unknown type is speified in the values of the mapper. Source code in etlrules/backends/pandas/types.py class TypeConversionRule ( UnaryOpBaseRule ): \"\"\" Converts the type of a given set of columns to other types. Args: mapper: A dict with columns names as keys and the new types as values. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: is raised when a column specified in the mapper doesn't exist in the input data frame. UnsupportedTypeError: is raised when an unknown type is speified in the values of the mapper. \"\"\" SUPPORTED_TYPES = { 'int32' , 'int64' , 'float64' , 'str' , } def __init__ ( self , mapper : Mapping [ str , str ], named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): assert isinstance ( mapper , dict ), \"mapper needs to be a dict {column_name:type}\" assert all ( isinstance ( key , str ) and isinstance ( val , str ) for key , val in mapper . items ()), \"mapper needs to be a dict {column_name:type} where the names are str\" super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . mapper = mapper def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) columns_set = set ( df . columns ) for column_name , type_str in self . mapper . items (): if column_name not in columns_set : raise MissingColumnError ( f \"Column ' { column_name } ' is missing in the data frame. Available columns: { sorted ( columns_set ) } \" ) if type_str not in self . SUPPORTED_TYPES : raise UnsupportedTypeError ( f \"Type ' { type_str } ' for column ' { column_name } ' is not currently supported.\" ) df = df . assign ( ** { column_name : df [ column_name ] . astype ( type_str ) for column_name , type_str in self . mapper . items ()}) self . _set_output_df ( data , df ) exceptions \u00b6 ColumnAlreadyExistsError ( Exception ) \u00b6 An attempt to create a column that already exists in the dataframe. Source code in etlrules/exceptions.py class ColumnAlreadyExistsError ( Exception ): \"\"\" An attempt to create a column that already exists in the dataframe. \"\"\" ExpressionSyntaxError ( SyntaxError ) \u00b6 A Python expression used to create a column, aggregate or other operations has a syntax error. Source code in etlrules/exceptions.py class ExpressionSyntaxError ( SyntaxError ): \"\"\" A Python expression used to create a column, aggregate or other operations has a syntax error. \"\"\" MissingColumnError ( Exception ) \u00b6 An operation is being applied to a column that is not present in the input data frame. Source code in etlrules/exceptions.py class MissingColumnError ( Exception ): \"\"\" An operation is being applied to a column that is not present in the input data frame. \"\"\" SchemaError ( Exception ) \u00b6 An operation needs a certain schema for the dataframe which is not present. Source code in etlrules/exceptions.py class SchemaError ( Exception ): \"\"\" An operation needs a certain schema for the dataframe which is not present. \"\"\" UnsupportedTypeError ( Exception ) \u00b6 A type conversion is attempted to a type that is not supported. Source code in etlrules/exceptions.py class UnsupportedTypeError ( Exception ): \"\"\" A type conversion is attempted to a type that is not supported. \"\"\" rule \u00b6 BinaryOpBaseRule ( BaseRule ) \u00b6 Base class for binary operation rules (ie operations taking two data frames as input). Source code in etlrules/rule.py class BinaryOpBaseRule ( BaseRule ): \"\"\" Base class for binary operation rules (ie operations taking two data frames as input). \"\"\" def __init__ ( self , named_input_left , named_input_right , named_output = None , name = None , description = None , strict = True ): super () . __init__ ( named_output = named_output , name = name , description = description , strict = strict ) assert named_input_left is None or isinstance ( named_input_left , str ) and named_input_left assert named_input_right is None or isinstance ( named_input_right , str ) and named_input_right assert named_input_left != named_input_right self . named_input_left = named_input_left self . named_input_right = named_input_right def _get_input_df_left ( self , data ): if self . named_input_left is None : return data . get_main_output () return data . get_named_output ( self . named_input_left ) def _get_input_df_right ( self , data ): if self . named_input_right is None : return data . get_main_output () return data . get_named_output ( self . named_input_right ) UnaryOpBaseRule ( BaseRule ) \u00b6 Base class for unary operation rules (ie operations taking a single data frame as input). Source code in etlrules/rule.py class UnaryOpBaseRule ( BaseRule ): \"\"\" Base class for unary operation rules (ie operations taking a single data frame as input). \"\"\" def __init__ ( self , named_input = None , named_output = None , name = None , description = None , strict = True ): super () . __init__ ( named_output = named_output , name = name , description = description , strict = strict ) assert named_input is None or isinstance ( named_input , str ) and named_input self . named_input = named_input def _get_input_df ( self , data ): if self . named_input is None : return data . get_main_output () return data . get_named_output ( self . named_input )","title":"API Reference"},{"location":"api/#etlrules.backends","text":"","title":"backends"},{"location":"api/#etlrules.backends.common","text":"","title":"common"},{"location":"api/#etlrules.backends.common.basic","text":"","title":"basic"},{"location":"api/#etlrules.backends.common.basic.RulesBlock","text":"Groups rules into encapsulated blocks or units of rules that achieve one thing. Blocks are reusable and encapsulated to reduce complexity. Parameters: Name Type Description Default rules Iterable[etlrules.rule.BaseRule] An iterable of rules which are part of this block. The first rule in the block will take its input from the named_input of the RulesBlock (if any, if not from the main output of the previous rule). The last rule in the block will publish the output as the named_output of the RulesBlock (if any, or the main output of the block). Any named outputs in the block are not exposed to the rules outside of the block (proper encapsulation). required Common params: !!! named_input \"Which dataframe to use as the input. Optional.\" When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. !!! named_output \"Give the output of this rule a name so it can be used by another rule as a named input. Optional.\" When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. !!! name \"Give the rule a name. Optional.\" Named rules are more descriptive as to what they're trying to do/the intent. !!! description \"Describe in detail what the rules does, how it does it. Optional.\" Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Source code in etlrules/backends/common/basic.py class RulesBlock ( UnaryOpBaseRule ): \"\"\" Groups rules into encapsulated blocks or units of rules that achieve one thing. Blocks are reusable and encapsulated to reduce complexity. Params: rules: An iterable of rules which are part of this block. The first rule in the block will take its input from the named_input of the RulesBlock (if any, if not from the main output of the previous rule). The last rule in the block will publish the output as the named_output of the RulesBlock (if any, or the main output of the block). Any named outputs in the block are not exposed to the rules outside of the block (proper encapsulation). Common params: named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True \"\"\" def __init__ ( self , rules : Iterable [ BaseRule ], named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): self . _rules = [ rule for rule in rules ] assert self . _rules , \"RulesBlock: Empty rules set provided.\" assert all ( isinstance ( rule , BaseRule ) for rule in self . _rules ), [ rule for rule in self . _rules if not isinstance ( rule , BaseRule )] assert self . _rules [ 0 ] . named_input is None , \"First rule in a RulesBlock must consume the main input/output\" assert self . _rules [ - 1 ] . named_input is None , \"Last rule in a RulesBlock must produce the main output\" super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) def apply ( self , data ): super () . apply ( data ) data2 = RuleData ( main_input = self . _get_input_df ( data ), named_inputs = { k : v for k , v in data . get_named_outputs ()}, strict = self . strict ) for rule in self . _rules : rule . apply ( data2 ) self . _set_output_df ( data , data2 . get_main_output ()) def to_dict ( self ): dct = super () . to_dict () dct [ self . __class__ . __name__ ][ \"rules\" ] = [ rule . to_dict () for rule in self . _rules ] return dct @classmethod def from_dict ( cls , dct , backend ): dct = dct [ \"RulesBlock\" ] rules = [ BaseRule . from_dict ( rule , backend ) for rule in dct . get ( \"rules\" , ())] kwargs = { k : v for k , v in dct . items () if k != \"rules\" } return cls ( rules = rules , ** kwargs )","title":"RulesBlock"},{"location":"api/#etlrules.backends.pandas","text":"","title":"pandas"},{"location":"api/#etlrules.backends.pandas.aggregate","text":"","title":"aggregate"},{"location":"api/#etlrules.backends.pandas.aggregate.AggregateRule","text":"Performs a SQL-like groupby and aggregation. It takes a list of columns to group by and the result will have one row for each unique combination of values in the group_by columns. The rest of the columns (not in the group_by) can be aggregated using either pre-defined aggregations or using custom python expressions. Parameters: Name Type Description Default group_by Iterable[str] A list of columns to group the result by required aggregations Optional[Mapping[str, str]] A mapping {column_name: aggregation_function} which specifies how to aggregate columns which are not in the group_by list. The following list of aggregation functions are supported:: 1 2 3 4 5 6 7 8 9 10 11 min: minimum of the values in the group max: minimum of the values in the group mean: The mathematical mean value in the group count: How many values are in the group, including NA countNoNA: How many values are in the group, excluding NA sum: The sum of the values in the group first: The first value in the group last: The last value in the group list: Produces a python list with all the values in the group, excluding NA tuple: Like list above but produces a tuple csv: Produces a comma separated string of values, exluding NA None aggregation_expressions Optional[Mapping[str, str]] A mapping {column_name: aggregation_expression} which specifies how to aggregate columns which are not in the group_by list. The aggregation expression is a string representing a valid Python expression which gets evaluated. The input will be in a variable values . isnull can be used to filter out NA. Example:: 1 2 3 {\"C\": \"';'.join(str(v) for v in values if not isnull(v))\"} The above aggregates the column C by producing a ; separated string of values in the group, excluding NA. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ColumnAlreadyExistsError raised if a column appears in multiple places in group_by/aggregations/aggregation_expressions. ExpressionSyntaxError raised if any aggregation expression (if any are passed in) has a Python syntax error. MissingColumnError raised in strict mode only if a column specified in aggregations or aggregation_expressions is missing from the input dataframe. ValueError raised if a column in aggregations is trying to be aggregated using an unknown aggregate function TypeError raised if an operation is not supported between the types involved NameError raised if an unknown variable is used Note Other Python exceptions can be raised when custom aggregation expressions are used, depending on what the expression is doing. Note Any columns not in the group_by list and not present in either aggregations or aggregation_expressions will be dropped from the result. Source code in etlrules/backends/pandas/aggregate.py class AggregateRule ( UnaryOpBaseRule ): \"\"\" Performs a SQL-like groupby and aggregation. It takes a list of columns to group by and the result will have one row for each unique combination of values in the group_by columns. The rest of the columns (not in the group_by) can be aggregated using either pre-defined aggregations or using custom python expressions. Args: group_by: A list of columns to group the result by aggregations: A mapping {column_name: aggregation_function} which specifies how to aggregate columns which are not in the group_by list. The following list of aggregation functions are supported:: min: minimum of the values in the group max: minimum of the values in the group mean: The mathematical mean value in the group count: How many values are in the group, including NA countNoNA: How many values are in the group, excluding NA sum: The sum of the values in the group first: The first value in the group last: The last value in the group list: Produces a python list with all the values in the group, excluding NA tuple: Like list above but produces a tuple csv: Produces a comma separated string of values, exluding NA aggregation_expressions: A mapping {column_name: aggregation_expression} which specifies how to aggregate columns which are not in the group_by list. The aggregation expression is a string representing a valid Python expression which gets evaluated. The input will be in a variable `values`. `isnull` can be used to filter out NA. Example:: {\"C\": \"';'.join(str(v) for v in values if not isnull(v))\"} The above aggregates the column C by producing a ; separated string of values in the group, excluding NA. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ColumnAlreadyExistsError: raised if a column appears in multiple places in group_by/aggregations/aggregation_expressions. ExpressionSyntaxError: raised if any aggregation expression (if any are passed in) has a Python syntax error. MissingColumnError: raised in strict mode only if a column specified in aggregations or aggregation_expressions is missing from the input dataframe. ValueError: raised if a column in aggregations is trying to be aggregated using an unknown aggregate function TypeError: raised if an operation is not supported between the types involved NameError: raised if an unknown variable is used Note: Other Python exceptions can be raised when custom aggregation expressions are used, depending on what the expression is doing. Note: Any columns not in the group_by list and not present in either aggregations or aggregation_expressions will be dropped from the result. \"\"\" AGGREGATIONS = { \"min\" : \"min\" , \"max\" : \"max\" , \"mean\" : \"mean\" , \"count\" : \"size\" , \"countNoNA\" : \"count\" , \"sum\" : \"sum\" , \"first\" : \"first\" , \"last\" : \"last\" , \"list\" : lambda values : [ value for value in values if not isnull ( value )], \"tuple\" : lambda values : tuple ( value for value in values if not isnull ( value )), \"csv\" : lambda values : \",\" . join ( str ( elem ) for elem in values if not isnull ( elem )), } EXCLUDE_FROM_COMPARE = ( '_aggs' ,) def __init__ ( self , group_by : Iterable [ str ], aggregations : Optional [ Mapping [ str , str ]] = None , aggregation_expressions : Optional [ Mapping [ str , str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . group_by = [ col for col in group_by ] assert aggregations or aggregation_expressions , \"aggregations or aggregation_expressions must be specified.\" for col , agg_func in ( aggregations or {}) . items (): if col in self . group_by : raise ColumnAlreadyExistsError ( f \"Column { col } appears in group_by and cannot be aggregated.\" ) if agg_func not in self . AGGREGATIONS : raise ValueError ( f \"' { agg_func } ' is not a supported aggregation function.\" ) self . aggregations = { key : agg_func for key , agg_func in ( aggregations or {}) . items ()} self . aggregation_expressions = { key : value for key , value in ( aggregation_expressions or {}) . items ()} self . _aggs = {} if self . aggregations : self . _aggs . update ({ key : self . AGGREGATIONS [ agg_func ] for key , agg_func in ( aggregations or {}) . items ()}) if self . aggregation_expressions : for col , agg_expr in self . aggregation_expressions . items (): if col in self . group_by : raise ColumnAlreadyExistsError ( f \"Column { col } appears in group_by and cannot be aggregated.\" ) if col in self . _aggs : raise ColumnAlreadyExistsError ( f \"Column { col } is already being aggregated.\" ) try : _ast_expr = ast . parse ( agg_expr , filename = f ' { col } _expression.py' , mode = 'eval' ) _compiled_expr = compile ( _ast_expr , filename = f ' { col } _expression.py' , mode = 'eval' ) self . _aggs [ col ] = lambda values , bound_compiled_expr = _compiled_expr : eval ( bound_compiled_expr , { 'isnull' : isnull }, { 'values' : values }) except SyntaxError as exc : raise ExpressionSyntaxError ( f \"Error in aggregation expression for column ' { col } ': ' { agg_expr } ': { str ( exc ) } \" ) def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) df_columns_set = set ( df . columns ) if not set ( self . _aggs ) <= df_columns_set : if self . strict : raise MissingColumnError ( f \"Missimg columns to aggregate by: { set ( self . _aggs ) - df_columns_set } \" ) aggs = { col : agg for col , agg in self . _aggs . items () if col in df_columns_set } else : aggs = self . _aggs df = df . groupby ( by = self . group_by , as_index = False , dropna = False ) . agg ( aggs ) self . _set_output_df ( data , df )","title":"AggregateRule"},{"location":"api/#etlrules.backends.pandas.basic","text":"","title":"basic"},{"location":"api/#etlrules.backends.pandas.basic.DedupeRule","text":"De-duplicates by dropping duplicates using a set of columns to determine the duplicates. It has logic to keep the first, last or none of the duplicate in a set of duplicates. Parameters: Name Type Description Default columns Iterable[str] A subset of columns in the data frame which are used to determine the set of duplicates. Any rows that have the same values in these columns are considered to be duplicates. required keep Literal['first', 'last', 'none'] What to keep in the de-duplication process. One of: first: keeps the first row in the duplicate set last: keeps the last row in the duplicate set none: drops all the duplicates 'first' named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised when a column specified to deduplicate on doesn't exist in the input data frame. Note MissingColumnError is raised in both strict and non-strict modes. This is because the rule cannot operate reliably without a correct set of columns. Source code in etlrules/backends/pandas/basic.py class DedupeRule ( UnaryOpBaseRule ): \"\"\" De-duplicates by dropping duplicates using a set of columns to determine the duplicates. It has logic to keep the first, last or none of the duplicate in a set of duplicates. Args: columns: A subset of columns in the data frame which are used to determine the set of duplicates. Any rows that have the same values in these columns are considered to be duplicates. keep: What to keep in the de-duplication process. One of: first: keeps the first row in the duplicate set last: keeps the last row in the duplicate set none: drops all the duplicates named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised when a column specified to deduplicate on doesn't exist in the input data frame. Note: MissingColumnError is raised in both strict and non-strict modes. This is because the rule cannot operate reliably without a correct set of columns. \"\"\" KEEP_FIRST = 'first' KEEP_LAST = 'last' KEEP_NONE = 'none' ALL_KEEPS = ( KEEP_FIRST , KEEP_LAST , KEEP_NONE ) def __init__ ( self , columns : Iterable [ str ], keep : Literal [ KEEP_FIRST , KEEP_LAST , KEEP_NONE ] = KEEP_FIRST , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . columns = [ col for col in columns ] assert all ( isinstance ( col , str ) for col in self . columns ), \"DedupeRule: columns must be strings\" assert keep in self . ALL_KEEPS , f \"DedupeRule: keep must be one of: { self . ALL_KEEPS } \" self . keep = False if keep == DedupeRule . KEEP_NONE else keep def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) if not set ( self . columns ) <= set ( df . columns ): raise MissingColumnError ( f \"Missing column(s) to dedupe on: { set ( self . columns ) - set ( df . columns ) } \" ) df = df . drop_duplicates ( subset = self . columns , keep = self . keep , ignore_index = True ) self . _set_output_df ( data , df )","title":"DedupeRule"},{"location":"api/#etlrules.backends.pandas.basic.ProjectRule","text":"Reshapes the data frame to keep, eliminate or re-order the set of columns. Parameters: Name Type Description Default columns Iterable[str] The list of columns to keep or eliminate from the data frame. The order of column names will be reflected in the result data frame, so this rule can be used to re-order columns. required exclude bool When set to True, the columns in the columns arg will be excluded from the data frame. Boolean. Default: False In strict mode, if any column specified in the columns arg doesn't exist in the input data frame, a MissingColumnError exception is raised. In non strict mode, the missing columns are ignored. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised in strict mode only, if any columns are missing from the input data frame. Source code in etlrules/backends/pandas/basic.py class ProjectRule ( BaseProjectRule , PandasRuleValidationMixin ): \"\"\" Reshapes the data frame to keep, eliminate or re-order the set of columns. Args: columns (Iterable[str]): The list of columns to keep or eliminate from the data frame. The order of column names will be reflected in the result data frame, so this rule can be used to re-order columns. exclude (bool): When set to True, the columns in the columns arg will be excluded from the data frame. Boolean. Default: False In strict mode, if any column specified in the columns arg doesn't exist in the input data frame, a MissingColumnError exception is raised. In non strict mode, the missing columns are ignored. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only, if any columns are missing from the input data frame. \"\"\" def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) remaining_columns = self . _get_remaining_columns ( df . columns ) df = df [ remaining_columns ] self . _set_output_df ( data , df )","title":"ProjectRule"},{"location":"api/#etlrules.backends.pandas.basic.RenameRule","text":"Renames a set of columns in the data frame. Parameters: Name Type Description Default mapper Mapping[str, str] A dictionary of old names (keys) and new names (values) to be used for the rename operation The order of column names will be reflected in the result data frame, so this rule can be used to re-order columns. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only, if any columns (keys) are missing from the input data frame. Source code in etlrules/backends/pandas/basic.py class RenameRule ( UnaryOpBaseRule ): \"\"\" Renames a set of columns in the data frame. Args: mapper: A dictionary of old names (keys) and new names (values) to be used for the rename operation The order of column names will be reflected in the result data frame, so this rule can be used to re-order columns. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only, if any columns (keys) are missing from the input data frame. \"\"\" def __init__ ( self , mapper : Mapping [ str , str ], named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): assert isinstance ( mapper , dict ), \"mapper needs to be a dict {old_name:new_name}\" assert all ( isinstance ( key , str ) and isinstance ( val , str ) for key , val in mapper . items ()), \"mapper needs to be a dict {old_name:new_name} where the names are str\" super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . mapper = mapper def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) if self . strict : if not set ( self . mapper . keys ()) <= set ( df . columns ): raise MissingColumnError ( f \"Missing columns to rename: { set ( self . mapper . keys ()) - set ( df . columns ) } \" ) df = df . rename ( columns = self . mapper ) self . _set_output_df ( data , df )","title":"RenameRule"},{"location":"api/#etlrules.backends.pandas.basic.ReplaceRule","text":"Replaces some some values (or regular expressions) with another set of values (or regular expressions) in a set of columns. Basic usage:: 1 2 3 4 5 6 7 # replaces A with new_A and b with new_b in col_A, col_B and col_C rule = ReplaceRule([\"col_A\", \"col_B\", \"col_C\"], values=[\"A\", \"b\"], new_values=[\"new_A\", \"new_b\"]) rule.apply(data) # replaces 1 with 3 and 2 with 4 in the col_I column rule = ReplaceRule([\"col_I\"], values=[1, 2], new_values=[3, 4]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required values Iterable[Union[int, float, str]] A sequence of values to replace. Regular expressions can be used to match values more widely, in which case, the regex parameter must be set to True. Values can be any supported types but they should match the type of the columns. required new_values Iterable[Union[int, float, str]] A sequence of the same length as values. Each value within new_values will replace the corresponding value in values (at the same index). New values can be any supported types but they should match the type of the columns. required regex True if all the values and new_values are to be interpreted as regular expressions. Default: False. regex=True is only applicable to string columns. False output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/basic.py class ReplaceRule ( BaseAssignRule ): \"\"\" Replaces some some values (or regular expressions) with another set of values (or regular expressions) in a set of columns. Basic usage:: # replaces A with new_A and b with new_b in col_A, col_B and col_C rule = ReplaceRule([\"col_A\", \"col_B\", \"col_C\"], values=[\"A\", \"b\"], new_values=[\"new_A\", \"new_b\"]) rule.apply(data) # replaces 1 with 3 and 2 with 4 in the col_I column rule = ReplaceRule([\"col_I\"], values=[1, 2], new_values=[3, 4]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. values: A sequence of values to replace. Regular expressions can be used to match values more widely, in which case, the regex parameter must be set to True. Values can be any supported types but they should match the type of the columns. new_values: A sequence of the same length as values. Each value within new_values will replace the corresponding value in values (at the same index). New values can be any supported types but they should match the type of the columns. regex: True if all the values and new_values are to be interpreted as regular expressions. Default: False. regex=True is only applicable to string columns. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , columns : Iterable [ str ], values : Iterable [ Union [ int , float , str ]], new_values : Iterable [ Union [ int , float , str ]], regex = False , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . values = [ val for val in values ] self . new_values = [ val for val in new_values ] assert len ( self . values ) == len ( self . new_values ), \"values and new_values must be of the same length.\" assert self . values , \"values must not be empty.\" self . regex = regex def do_apply ( self , col ): return col . replace ( to_replace = self . values , value = self . new_values , regex = self . regex )","title":"ReplaceRule"},{"location":"api/#etlrules.backends.pandas.basic.SortRule","text":"Sort the input dataframe by the given columns, either ascending or descending. Parameters: Name Type Description Default sort_by Iterable[str] Either a single column speified as a string or a list or tuple of columns to sort by required ascending Union[bool, Iterable[bool]] Whether to sort ascending or descending. Boolean. Default: True True named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Note When multiple columns are specified, the first column decides the sort order. For any rows that have the same value in the first column, the second column is used to decide the sort order within that group and so on. Source code in etlrules/backends/pandas/basic.py class SortRule ( UnaryOpBaseRule ): \"\"\" Sort the input dataframe by the given columns, either ascending or descending. Args: sort_by: Either a single column speified as a string or a list or tuple of columns to sort by ascending: Whether to sort ascending or descending. Boolean. Default: True named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Note: When multiple columns are specified, the first column decides the sort order. For any rows that have the same value in the first column, the second column is used to decide the sort order within that group and so on. \"\"\" def __init__ ( self , sort_by : Iterable [ str ], ascending : Union [ bool , Iterable [ bool ]] = True , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . sort_by = [ col for col in sort_by ] if isinstance ( self . sort_by , str ): self . sort_by = [ self . sort_by ] assert isinstance ( ascending , bool ) or ( isinstance ( ascending , ( list , tuple )) and all ( isinstance ( val , bool ) for val in ascending ) and len ( ascending ) == len ( self . sort_by )), \"ascending must be a bool or a list of bool of the same len as sort_by\" self . ascending = ascending def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) df = df . sort_values ( by = self . sort_by , ascending = self . ascending , ignore_index = True ) self . _set_output_df ( data , df )","title":"SortRule"},{"location":"api/#etlrules.backends.pandas.concat","text":"","title":"concat"},{"location":"api/#etlrules.backends.pandas.concat.HConcatRule","text":"Horizontally concatenates two dataframe with the result having the columns from the left dataframe followed by the columns from the right dataframe. The columns from the left dataframe will be followed by the columns from the right dataframe in the result dataframe. The two dataframes must not have columns with the same name. Example:: 1 2 3 4 5 6 7 8 9 10 11 Left dataframe: | A | B | | a | 1 | | b | 2 | | c | 3 | Right dataframe: | C | D | | d | 4 | | e | 5 | | f | 6 | After a concat(left, right), the result will look like:: 1 2 3 4 | A | B | C | D | | a | 1 | d | 4 | | b | 2 | e | 5 | | c | 3 | f | 6 | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ColumnAlreadyExistsError raised if the two dataframes have columns with the same name. SchemaError raised in strict mode only if the two dataframes have different number of rows. Source code in etlrules/backends/pandas/concat.py class HConcatRule ( BinaryOpBaseRule ): \"\"\" Horizontally concatenates two dataframe with the result having the columns from the left dataframe followed by the columns from the right dataframe. The columns from the left dataframe will be followed by the columns from the right dataframe in the result dataframe. The two dataframes must not have columns with the same name. Example:: Left dataframe: | A | B | | a | 1 | | b | 2 | | c | 3 | Right dataframe: | C | D | | d | 4 | | e | 5 | | f | 6 | After a concat(left, right), the result will look like:: | A | B | C | D | | a | 1 | d | 4 | | b | 2 | e | 5 | | c | 3 | f | 6 | Args: named_input_left: Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right: Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ColumnAlreadyExistsError: raised if the two dataframes have columns with the same name. SchemaError: raised in strict mode only if the two dataframes have different number of rows. \"\"\" def __init__ ( self , named_input_left : Optional [ str ], named_input_right : Optional [ str ], subset_columns : Optional [ Iterable [ str ]] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): # This __init__ not really needed but the type annotations are extracted from it super () . __init__ ( named_input_left = named_input_left , named_input_right = named_input_right , named_output = named_output , name = name , description = description , strict = strict ) def apply ( self , data ): super () . apply ( data ) left_df = self . _get_input_df_left ( data ) right_df = self . _get_input_df_right ( data ) overlapping_names = set ( left_df . columns ) & set ( right_df . columns ) if overlapping_names : raise ColumnAlreadyExistsError ( f \"Column(s) { overlapping_names } exist in both dataframes.\" ) if self . strict : if len ( left_df ) != len ( right_df ): raise SchemaError ( f \"HConcat needs the two dataframe to have the same number of rows. left df= { len ( left_df ) } rows, right df= { len ( right_df ) } rows.\" ) df = concat ([ left_df , right_df ], axis = 1 ) self . _set_output_df ( data , df )","title":"HConcatRule"},{"location":"api/#etlrules.backends.pandas.concat.VConcatRule","text":"Vertically concatenates two dataframe with the result having the rows from the left dataframe followed by the rows from the right dataframe. The rows of the right dataframe are added at the bottom of the rows from the left dataframe in the result dataframe. Example:: 1 2 3 4 5 6 7 8 9 10 11 Left dataframe: | A | B | | a | 1 | | b | 2 | | c | 3 | Right dataframe: | A | B | | d | 4 | | e | 5 | | f | 6 | After a concat(left, right), the result will look like:: 1 2 3 4 5 6 7 | A | B | | a | 1 | | b | 2 | | c | 3 | | d | 4 | | e | 5 | | f | 6 | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required subset_columns Optional[Iterable[str]] A subset list of columns available in both dataframes. Only these columns will be concated. The effect is similar to doing a ProjectRule(subset_columns) on both dataframes before the concat. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised if any subset columns specified are missing from any of the dataframe. SchemaError raised in strict mode only if the columns differ between the two dataframes and subset_columns is not specified. Note In strict mode, as described above, SchemaError is raised if the columns are not the same (names, types can be inferred). In non-strict mode, columns are not checked and values are filled with NA when missing. Source code in etlrules/backends/pandas/concat.py class VConcatRule ( BinaryOpBaseRule ): \"\"\" Vertically concatenates two dataframe with the result having the rows from the left dataframe followed by the rows from the right dataframe. The rows of the right dataframe are added at the bottom of the rows from the left dataframe in the result dataframe. Example:: Left dataframe: | A | B | | a | 1 | | b | 2 | | c | 3 | Right dataframe: | A | B | | d | 4 | | e | 5 | | f | 6 | After a concat(left, right), the result will look like:: | A | B | | a | 1 | | b | 2 | | c | 3 | | d | 4 | | e | 5 | | f | 6 | Args: named_input_left: Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right: Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. subset_columns: A subset list of columns available in both dataframes. Only these columns will be concated. The effect is similar to doing a ProjectRule(subset_columns) on both dataframes before the concat. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any subset columns specified are missing from any of the dataframe. SchemaError: raised in strict mode only if the columns differ between the two dataframes and subset_columns is not specified. Note: In strict mode, as described above, SchemaError is raised if the columns are not the same (names, types can be inferred). In non-strict mode, columns are not checked and values are filled with NA when missing. \"\"\" def __init__ ( self , named_input_left : Optional [ str ], named_input_right : Optional [ str ], subset_columns : Optional [ Iterable [ str ]] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input_left = named_input_left , named_input_right = named_input_right , named_output = named_output , name = name , description = description , strict = strict ) self . subset_columns = [ col for col in subset_columns ] if subset_columns is not None else None def apply ( self , data ): super () . apply ( data ) left_df = self . _get_input_df_left ( data ) right_df = self . _get_input_df_right ( data ) if self . subset_columns : if not set ( self . subset_columns ) <= set ( left_df . columns ): raise MissingColumnError ( f \"Missing columns in the left dataframe of the concat operation: { set ( self . subset_columns ) - set ( left_df . columns ) } \" ) if not set ( self . subset_columns ) <= set ( right_df . columns ): raise MissingColumnError ( f \"Missing columns in the right dataframe of the concat operation: { set ( self . subset_columns ) - set ( right_df . columns ) } \" ) left_df = left_df [ self . subset_columns ] right_df = right_df [ self . subset_columns ] if self . strict : if set ( left_df . columns ) != set ( right_df . columns ): raise SchemaError ( f \"VConcat needs both dataframe have the same schema. Missing columns in the right df: { set ( right_df . columns ) - set ( left_df . columns ) } . Missing columns in the left df: { set ( left_df . columns ) - set ( right_df . columns ) } \" ) df = concat ([ left_df , right_df ], axis = 0 , ignore_index = True ) self . _set_output_df ( data , df )","title":"VConcatRule"},{"location":"api/#etlrules.backends.pandas.conditions","text":"","title":"conditions"},{"location":"api/#etlrules.backends.pandas.conditions.FilterRule","text":"Exclude rows based on a condition. Example:: 1 2 3 4 5 6 7 8 Given df: | A | B | | 1 | 2 | | 5 | 3 | | 3 | 4 | rule = FilterRule(\"df['A'] > df['B']\") rule.apply(df) Result:: 1 2 | A | B | | 5 | 3 | Same example using discarded_matching_rows=True:: 1 2 rule = FilterRule(\"df['A'] > df['B']\", discard_matching_rows=True) rule.apply(df) Result:: 1 2 3 | A | B | | 1 | 2 | | 3 | 4 | Parameters: Name Type Description Default condition_expression str An expression as a string. The expression must evaluate to a boolean scalar or a boolean series. required discard_matching_rows bool By default the rows matching the condition (ie where the condition is True) are kept, the rest of the rows being dropped from the result. Setting this parameter to True essentially inverts the condition, so the rows matching the condition are discarded and the rest of the rows kept. Default: False. False named_output_discarded Optional[str] A named output for the records being discarded if those need to be kept for further processing. Default: None, which doesn't keep track of discarded records. None output_column The column name of the result column which will be added to the dataframe. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ExpressionSyntaxError raised if the column expression has a Python syntax error. TypeError raised if an operation is not supported between the types involved NameError raised if an unknown variable is used KeyError raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) Source code in etlrules/backends/pandas/conditions.py class FilterRule ( UnaryOpBaseRule ): \"\"\" Exclude rows based on a condition. Example:: Given df: | A | B | | 1 | 2 | | 5 | 3 | | 3 | 4 | rule = FilterRule(\"df['A'] > df['B']\") rule.apply(df) Result:: | A | B | | 5 | 3 | Same example using discarded_matching_rows=True:: rule = FilterRule(\"df['A'] > df['B']\", discard_matching_rows=True) rule.apply(df) Result:: | A | B | | 1 | 2 | | 3 | 4 | Args: condition_expression: An expression as a string. The expression must evaluate to a boolean scalar or a boolean series. discard_matching_rows: By default the rows matching the condition (ie where the condition is True) are kept, the rest of the rows being dropped from the result. Setting this parameter to True essentially inverts the condition, so the rows matching the condition are discarded and the rest of the rows kept. Default: False. named_output_discarded: A named output for the records being discarded if those need to be kept for further processing. Default: None, which doesn't keep track of discarded records. output_column: The column name of the result column which will be added to the dataframe. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ExpressionSyntaxError: raised if the column expression has a Python syntax error. TypeError: raised if an operation is not supported between the types involved NameError: raised if an unknown variable is used KeyError: raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) \"\"\" EXCLUDE_FROM_COMPARE = ( '_condition_expression' , ) def __init__ ( self , condition_expression : str , discard_matching_rows : bool = False , named_output_discarded : Optional [ str ] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert condition_expression , \"condition_expression cannot be empty\" self . condition_expression = condition_expression self . discard_matching_rows = discard_matching_rows self . named_output_discarded = named_output_discarded self . _condition_expression = Expression ( self . condition_expression , filename = \"FilterRule.py\" ) def apply ( self , data ): df = self . _get_input_df ( data ) cond_series = self . _condition_expression . eval ( df ) if self . discard_matching_rows : cond_series = ~ cond_series self . _set_output_df ( data , df [ cond_series ] . reset_index ( drop = True )) if self . named_output_discarded : data . set_named_output ( self . named_output_discarded , df [ ~ cond_series ] . reset_index ( drop = True ))","title":"FilterRule"},{"location":"api/#etlrules.backends.pandas.conditions.IfThenElseRule","text":"Calculates the ouput based on a condition (If Cond is true Then use then_value Else use else_value). Example:: 1 2 3 4 5 6 7 8 Given df: | A | B | | 1 | 2 | | 5 | 3 | | 3 | 4 | rule = IfThenElseRule(\"df['A'] > df['B']\", output_column=\"C\", then_value=\"A is greater\", else_value=\"B is greater\") rule.apply(df) Result:: 1 2 3 4 | A | B | C | | 1 | 2 | B is greater | | 5 | 3 | A is greater | | 3 | 4 | B is greater | Parameters: Name Type Description Default condition_expression str An expression as a string. The expression must evaluate to a boolean scalar or a boolean series. required then_value Union[int, float, bool, str] The value to use if the condition is true. None then_column Optional[str] Use the value from the then_column if the condition is true. One and only one of then_value and then_column can be used. None else_value Union[int, float, bool, str] The value to use if the condition is false. None else_column Optional[str] Use the value from the else_column if the condition is false. One and only one of the else_value and else_column can be used. None output_column str The column name of the result column which will be added to the dataframe. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ColumnAlreadyExistsError raised in strict mode only if a column with the same name already exists in the dataframe. ExpressionSyntaxError raised if the column expression has a Python syntax error. MissingColumnError raised when then_column or else_column are used but they are missing from the input dataframe. TypeError raised if an operation is not supported between the types involved NameError raised if an unknown variable is used KeyError raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) Source code in etlrules/backends/pandas/conditions.py class IfThenElseRule ( UnaryOpBaseRule ): \"\"\" Calculates the ouput based on a condition (If Cond is true Then use then_value Else use else_value). Example:: Given df: | A | B | | 1 | 2 | | 5 | 3 | | 3 | 4 | rule = IfThenElseRule(\"df['A'] > df['B']\", output_column=\"C\", then_value=\"A is greater\", else_value=\"B is greater\") rule.apply(df) Result:: | A | B | C | | 1 | 2 | B is greater | | 5 | 3 | A is greater | | 3 | 4 | B is greater | Args: condition_expression: An expression as a string. The expression must evaluate to a boolean scalar or a boolean series. then_value: The value to use if the condition is true. then_column: Use the value from the then_column if the condition is true. One and only one of then_value and then_column can be used. else_value: The value to use if the condition is false. else_column: Use the value from the else_column if the condition is false. One and only one of the else_value and else_column can be used. output_column: The column name of the result column which will be added to the dataframe. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ColumnAlreadyExistsError: raised in strict mode only if a column with the same name already exists in the dataframe. ExpressionSyntaxError: raised if the column expression has a Python syntax error. MissingColumnError: raised when then_column or else_column are used but they are missing from the input dataframe. TypeError: raised if an operation is not supported between the types involved NameError: raised if an unknown variable is used KeyError: raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) \"\"\" EXCLUDE_FROM_COMPARE = ( '_condition_expression' , ) def __init__ ( self , condition_expression : str , output_column : str , then_value : Optional [ Union [ int , float , bool , str ]] = None , then_column : Optional [ str ] = None , else_value : Optional [ Union [ int , float , bool , str ]] = None , else_column : Optional [ str ] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert bool ( then_value is None ) != bool ( then_column is None ), \"One and only one of then_value and then_column can be specified.\" assert bool ( else_value is None ) != bool ( else_column is None ), \"One and only one of else_value and else_column can be specified.\" assert condition_expression , \"condition_expression cannot be empty\" assert output_column , \"output_column cannot be empty\" self . condition_expression = condition_expression self . output_column = output_column self . then_value = then_value self . then_column = then_column self . else_value = else_value self . else_column = else_column self . _condition_expression = Expression ( self . condition_expression , filename = f ' { self . output_column } .py' ) def apply ( self , data ): df = self . _get_input_df ( data ) df_columns = set ( df . columns ) if self . strict and self . output_column in df_columns : raise ColumnAlreadyExistsError ( f \"Column { self . output_column } already exists in the input dataframe.\" ) if self . then_column is not None and self . then_column not in df_columns : raise MissingColumnError ( f \"Column { self . then_column } is missing from the input dataframe.\" ) if self . else_column is not None and self . else_column not in df_columns : raise MissingColumnError ( f \"Column { self . else_column } is missing from the input dataframe.\" ) cond_series = self . _condition_expression . eval ( df ) then_value = self . then_value if self . then_value is not None else df [ self . then_column ] else_value = self . else_value if self . else_value is not None else df [ self . else_column ] result = np . where ( cond_series , then_value , else_value ) df = df . assign ( ** { self . output_column : result }) self . _set_output_df ( data , df )","title":"IfThenElseRule"},{"location":"api/#etlrules.backends.pandas.fill","text":"","title":"fill"},{"location":"api/#etlrules.backends.pandas.fill.BackFillRule","text":"Replaces NAs/missing values with the next non-NA value, optionally sorting and grouping the data. Example:: 1 2 3 4 | A | B | | a | NA | | b | 2 | | a | NA | After a fill forward:: 1 2 3 4 | A | B | | a | 2 | | b | 2 | | a | NA | After a fill forward with group_by=[\"A\"]:: 1 2 3 4 | A | B | | a | NA | | b | 2 | | a | NA | The \"a\" group has no non-NA value, so it is not filled. The \"b\" group has a non-NA value of 2 but not other NA values, so nothing to fill. Parameters: Name Type Description Default columns Iterable[str] The list of columns to replaces NAs for. The rest of the columns in the dataframe are not affected. required sort_by Optional[Iterable[str]] The list of columns to sort by before the fill operation. Optional. Given the previous non-NA values are used, sorting can make a difference in the values uses. required sort_ascending bool When sort_by is specified, True means sort ascending, False sort descending. required group_by Optional[Iterable[str]] The list of columns to group by before the fill operation. Optional. The fill values are only used within a group, other adjacent groups are not filled. Useful when you want to copy(fill) data at a certain group level. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns specified in either columns, sort_by or group_by are missing from the dataframe. Source code in etlrules/backends/pandas/fill.py class BackFillRule ( BaseFillRule ): \"\"\" Replaces NAs/missing values with the next non-NA value, optionally sorting and grouping the data. Example:: | A | B | | a | NA | | b | 2 | | a | NA | After a fill forward:: | A | B | | a | 2 | | b | 2 | | a | NA | After a fill forward with group_by=[\"A\"]:: | A | B | | a | NA | | b | 2 | | a | NA | The \"a\" group has no non-NA value, so it is not filled. The \"b\" group has a non-NA value of 2 but not other NA values, so nothing to fill. Args: columns (Iterable[str]): The list of columns to replaces NAs for. The rest of the columns in the dataframe are not affected. sort_by (Optional[Iterable[str]]): The list of columns to sort by before the fill operation. Optional. Given the previous non-NA values are used, sorting can make a difference in the values uses. sort_ascending (bool): When sort_by is specified, True means sort ascending, False sort descending. group_by (Optional[Iterable[str]]): The list of columns to group by before the fill operation. Optional. The fill values are only used within a group, other adjacent groups are not filled. Useful when you want to copy(fill) data at a certain group level. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns specified in either columns, sort_by or group_by are missing from the dataframe. \"\"\" FILL_METHOD = \"bfill\"","title":"BackFillRule"},{"location":"api/#etlrules.backends.pandas.fill.ForwardFillRule","text":"Replaces NAs/missing values with the next non-NA value, optionally sorting and grouping the data. Example:: 1 2 3 4 | A | B | | a | 1 | | b | NA | | a | NA | After a fill forward:: 1 2 3 4 | A | B | | a | 1 | | b | 1 | | a | 1 | After a fill forward with group_by=[\"A\"]:: 1 2 3 4 | A | B | | a | 1 | | b | NA | | a | 1 | The \"a\" group has the first non-NA value as 1 and that is used \"forward\" to fill the 3rd row. The \"b\" group has no non-NA values, so nothing to fill. Parameters: Name Type Description Default columns Iterable[str] The list of columns to replaces NAs for. The rest of the columns in the dataframe are not affected. required sort_by Optional[Iterable[str]] The list of columns to sort by before the fill operation. Optional. Given the previous non-NA values are used, sorting can make a difference in the values uses. required sort_ascending bool When sort_by is specified, True means sort ascending, False sort descending. required group_by Optional[Iterable[str]] The list of columns to group by before the fill operation. Optional. The fill values are only used within a group, other adjacent groups are not filled. Useful when you want to copy(fill) data at a certain group level. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns specified in either columns, sort_by or group_by are missing from the dataframe. Source code in etlrules/backends/pandas/fill.py class ForwardFillRule ( BaseFillRule ): \"\"\" Replaces NAs/missing values with the next non-NA value, optionally sorting and grouping the data. Example:: | A | B | | a | 1 | | b | NA | | a | NA | After a fill forward:: | A | B | | a | 1 | | b | 1 | | a | 1 | After a fill forward with group_by=[\"A\"]:: | A | B | | a | 1 | | b | NA | | a | 1 | The \"a\" group has the first non-NA value as 1 and that is used \"forward\" to fill the 3rd row. The \"b\" group has no non-NA values, so nothing to fill. Args: columns (Iterable[str]): The list of columns to replaces NAs for. The rest of the columns in the dataframe are not affected. sort_by (Optional[Iterable[str]]): The list of columns to sort by before the fill operation. Optional. Given the previous non-NA values are used, sorting can make a difference in the values uses. sort_ascending (bool): When sort_by is specified, True means sort ascending, False sort descending. group_by (Optional[Iterable[str]]): The list of columns to group by before the fill operation. Optional. The fill values are only used within a group, other adjacent groups are not filled. Useful when you want to copy(fill) data at a certain group level. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description Optional[str]: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns specified in either columns, sort_by or group_by are missing from the dataframe. \"\"\" FILL_METHOD = \"ffill\"","title":"ForwardFillRule"},{"location":"api/#etlrules.backends.pandas.joins","text":"","title":"joins"},{"location":"api/#etlrules.backends.pandas.joins.InnerJoinRule","text":"Performs a database-style inner join operation on two data frames. A join involves two data frames left_df right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. An inner join specifies that only those rows that have key values in both left and right will be copied over and merged into the result data frame. Any rows without corresponding values on the other side (be it left or right) will be dropped from the result. Examples: left dataframe:: 1 2 3 | A | B | | 1 | a | | 2 | b | right dataframe:: 1 2 3 | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: 1 2 | A | B | C | | 1 | a | c | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required key_columns_left Iterable[str] A list or tuple of column names to join on (columns in the left data frame) required key_columns_right Optional[Iterable[str]] A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. required suffixes Iterable[Optional[str]] A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns (keys) are missing from any of the two input data frames. Source code in etlrules/backends/pandas/joins.py class InnerJoinRule ( BaseJoinRule ): \"\"\" Performs a database-style inner join operation on two data frames. A join involves two data frames left_df <join> right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. An inner join specifies that only those rows that have key values in both left and right will be copied over and merged into the result data frame. Any rows without corresponding values on the other side (be it left or right) will be dropped from the result. Example: left dataframe:: | A | B | | 1 | a | | 2 | b | right dataframe:: | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: | A | B | C | | 1 | a | c | Args: named_input_left (Optional[str]): Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right (Optional[str]): Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. key_columns_left (Iterable[str]): A list or tuple of column names to join on (columns in the left data frame) key_columns_right (Optional[Iterable[str]]): A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. suffixes (Iterable[Optional[str]]): A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns (keys) are missing from any of the two input data frames. \"\"\" JOIN_TYPE = \"inner\"","title":"InnerJoinRule"},{"location":"api/#etlrules.backends.pandas.joins.LeftJoinRule","text":"Performs a database-style left join operation on two data frames. A join involves two data frames left_df right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. A left join specifies that all the rows in the left dataframe will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the right dataframe. The right columns will be populated with NaNs/None when there is no corresponding row on the right. Examples: left dataframe:: 1 2 3 | A | B | | 1 | a | | 2 | b | right dataframe:: 1 2 3 | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: 1 2 3 | A | B | C | | 1 | a | c | | 2 | b | NA | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required key_columns_left Iterable[str] A list or tuple of column names to join on (columns in the left data frame) required key_columns_right Optional[Iterable[str]] A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. required suffixes Iterable[Optional[str]] A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns (keys) are missing from any of the two input data frames. Source code in etlrules/backends/pandas/joins.py class LeftJoinRule ( BaseJoinRule ): \"\"\" Performs a database-style left join operation on two data frames. A join involves two data frames left_df <join> right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. A left join specifies that all the rows in the left dataframe will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the right dataframe. The right columns will be populated with NaNs/None when there is no corresponding row on the right. Example: left dataframe:: | A | B | | 1 | a | | 2 | b | right dataframe:: | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: | A | B | C | | 1 | a | c | | 2 | b | NA | Args: named_input_left (Optional[str]): Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right (Optional[str]): Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. key_columns_left (Iterable[str]): A list or tuple of column names to join on (columns in the left data frame) key_columns_right (Optional[Iterable[str]]): A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. suffixes (Iterable[Optional[str]]): A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns (keys) are missing from any of the two input data frames. \"\"\" JOIN_TYPE = \"left\"","title":"LeftJoinRule"},{"location":"api/#etlrules.backends.pandas.joins.OuterJoinRule","text":"Performs a database-style left join operation on two data frames. A join involves two data frames left_df right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. An outer join specifies that all the rows in the both left and right dataframes will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the other dataframe. The missing side will have its columns populated with NA when the rows are missing. Examples: left dataframe:: 1 2 3 | A | B | | 1 | a | | 2 | b | right dataframe:: 1 2 3 | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: 1 2 3 4 | A | B | C | | 1 | a | c | | 2 | b | NA | | 3 | NA | d | Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required key_columns_left Iterable[str] A list or tuple of column names to join on (columns in the left data frame) required key_columns_right Optional[Iterable[str]] A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. required suffixes Iterable[Optional[str]] A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns (keys) are missing from any of the two input data frames. Source code in etlrules/backends/pandas/joins.py class OuterJoinRule ( BaseJoinRule ): \"\"\" Performs a database-style left join operation on two data frames. A join involves two data frames left_df <join> right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. An outer join specifies that all the rows in the both left and right dataframes will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the other dataframe. The missing side will have its columns populated with NA when the rows are missing. Example: left dataframe:: | A | B | | 1 | a | | 2 | b | right dataframe:: | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: | A | B | C | | 1 | a | c | | 2 | b | NA | | 3 | NA | d | Args: named_input_left (Optional[str]): Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right (Optional[str]): Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. key_columns_left (Iterable[str]): A list or tuple of column names to join on (columns in the left data frame) key_columns_right (Optional[Iterable[str]]): A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. suffixes (Iterable[Optional[str]]): A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns (keys) are missing from any of the two input data frames. \"\"\" JOIN_TYPE = \"outer\"","title":"OuterJoinRule"},{"location":"api/#etlrules.backends.pandas.joins.RightJoinRule","text":"Performs a database-style left join operation on two data frames. A join involves two data frames left_df right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. A right join specifies that all the rows in the right dataframe will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the left dataframe. The left columns will be populated with NA when there is no corresponding row on the left. Examples: left dataframe:: 1 2 3 | A | B | | 1 | a | | 2 | b | right dataframe:: 1 2 3 | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: 1 2 3 | A | B | C | | 1 | a | c | | 3 | NA | d | Note A right join is equivalent to a left join with the dataframes inverted, ie: left_df right_df is equivalent to right_df left_df although the order of the rows will be different. Parameters: Name Type Description Default named_input_left Optional[str] Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required named_input_right Optional[str] Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. required key_columns_left Iterable[str] A list or tuple of column names to join on (columns in the left data frame) required key_columns_right Optional[Iterable[str]] A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. required suffixes Iterable[Optional[str]] A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised if any columns (keys) are missing from any of the two input data frames. Source code in etlrules/backends/pandas/joins.py class RightJoinRule ( BaseJoinRule ): \"\"\" Performs a database-style left join operation on two data frames. A join involves two data frames left_df <join> right_df with the result performing a database style join or a merge of the two, with the resulting columns coming from both dataframes. For example, if the left dataframe has two columns A, B and the right dataframe has two column A, C, and assuming A is the key column the result will have three columns A, B, C. The rows that have the same value in the key column A will be merged on the same row in the result dataframe. A right join specifies that all the rows in the right dataframe will be present in the result, irrespective of whether there's a corresponding row with the same values in the key columns in the left dataframe. The left columns will be populated with NA when there is no corresponding row on the left. Example: left dataframe:: | A | B | | 1 | a | | 2 | b | right dataframe:: | A | C | | 1 | c | | 3 | d | result (key columns=[\"A\"]):: | A | B | C | | 1 | a | c | | 3 | NA | d | Note: A right join is equivalent to a left join with the dataframes inverted, ie: left_df <left_join> right_df is equivalent to right_df <right_join> left_df although the order of the rows will be different. Args: named_input_left (Optional[str]): Which dataframe to use as the input on the left side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. named_input_right (Optional[str]): Which dataframe to use as the input on the right side of the join. When set to None, the input is taken from the main output of the previous rule. Set it to a string value, the name of an output dataframe of a previous rule. key_columns_left (Iterable[str]): A list or tuple of column names to join on (columns in the left data frame) key_columns_right (Optional[Iterable[str]]): A list or tuple of column names to join on (columns in the right data frame). If not set or set to None, the key_columns_left is used on the right dataframe too. suffixes (Iterable[Optional[str]]): A list or tuple of two values which will be set as suffixes for the columns in the result data frame for those columns that have the same name (and are not key columns). named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised if any columns (keys) are missing from any of the two input data frames. \"\"\" JOIN_TYPE = \"right\"","title":"RightJoinRule"},{"location":"api/#etlrules.backends.pandas.newcolumns","text":"","title":"newcolumns"},{"location":"api/#etlrules.backends.pandas.newcolumns.AddNewColumnRule","text":"Adds a new column and sets it to the value of an evaluated expression. Example:: 1 2 3 4 5 Given df: | A | B | | 1 | 2 | | 2 | 3 | | 3 | 4 | AddNewColumnRule(\"Sum\", \"df['A'] + df['B']\").apply(df) Result:: 1 2 3 4 | A | B | Sum | | 1 | 2 | 3 | | 2 | 3 | 5 | | 3 | 4 | 7 | Parameters: Name Type Description Default column_name str The name of the new column to be added. required column_expression str An expression that gets evaluated and produces the value for the new column. The syntax: df[\"EXISTING_COL\"] can be used in the expression to refer to other columns in the dataframe. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description ColumnAlreadyExistsError raised in strict mode only if a column with the same name already exists in the dataframe. ExpressionSyntaxError raised if the column expression has a Python syntax error. TypeError raised if an operation is not supported between the types involved NameError raised if an unknown variable is used KeyError raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) Note The implementation will try to use dataframe operations for performance, but when those are not supported it will fallback to row level operations. Note NA are treated slightly differently between dataframe level operations and row level. At dataframe level operations, NAs in operations will make the result be NA. In row level operations, NAs will generally raise a TypeError. To avoid such behavior, fill the NAs before performing operations. Source code in etlrules/backends/pandas/newcolumns.py class AddNewColumnRule ( UnaryOpBaseRule ): \"\"\" Adds a new column and sets it to the value of an evaluated expression. Example:: Given df: | A | B | | 1 | 2 | | 2 | 3 | | 3 | 4 | > AddNewColumnRule(\"Sum\", \"df['A'] + df['B']\").apply(df) Result:: | A | B | Sum | | 1 | 2 | 3 | | 2 | 3 | 5 | | 3 | 4 | 7 | Args: column_name: The name of the new column to be added. column_expression: An expression that gets evaluated and produces the value for the new column. The syntax: df[\"EXISTING_COL\"] can be used in the expression to refer to other columns in the dataframe. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: ColumnAlreadyExistsError: raised in strict mode only if a column with the same name already exists in the dataframe. ExpressionSyntaxError: raised if the column expression has a Python syntax error. TypeError: raised if an operation is not supported between the types involved NameError: raised if an unknown variable is used KeyError: raised if you try to use an unknown column (i.e. df['ANY_UNKNOWN_COLUMN']) Note: The implementation will try to use dataframe operations for performance, but when those are not supported it will fallback to row level operations. Note: NA are treated slightly differently between dataframe level operations and row level. At dataframe level operations, NAs in operations will make the result be NA. In row level operations, NAs will generally raise a TypeError. To avoid such behavior, fill the NAs before performing operations. \"\"\" EXCLUDE_FROM_COMPARE = ( '_column_expression' , ) def __init__ ( self , column_name : str , column_expression : str , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . column_name = column_name self . column_expression = column_expression self . _column_expression = Expression ( self . column_expression , filename = f ' { self . column_name } _expression.py' ) def apply ( self , data ): df = self . _get_input_df ( data ) if self . strict and self . column_name in df . columns : raise ColumnAlreadyExistsError ( f \"Column { self . column_name } already exists in the input dataframe.\" ) result = self . _column_expression . eval ( df ) df = df . assign ( ** { self . column_name : result }) self . _set_output_df ( data , df )","title":"AddNewColumnRule"},{"location":"api/#etlrules.backends.pandas.numeric","text":"","title":"numeric"},{"location":"api/#etlrules.backends.pandas.numeric.AbsRule","text":"Converts numbers to absolute values. Basic usage:: 1 2 rule = AbsRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of numeric columns to convert to absolute values. required output_columns Optional[Iterable[str]] A list of new names for the columns with the absolute values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the absolute values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/numeric.py class AbsRule ( UnaryOpBaseRule , ColumnsInOutMixin ): \"\"\" Converts numbers to absolute values. Basic usage:: rule = AbsRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Args: columns: A list of numeric columns to convert to absolute values. output_columns: A list of new names for the columns with the absolute values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the absolute values. If not provided, the result is updated in place. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , columns : Iterable [ str ], output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . columns = [ col for col in columns ] self . output_columns = [ out_col for out_col in output_columns ] if output_columns else None def apply ( self , data ): df = self . _get_input_df ( data ) columns , output_columns = self . validate_columns_in_out ( df , self . columns , self . output_columns , self . strict ) abs_df = df [ columns ] . abs () df = df . assign ( ** { output_col : abs_df [ col ] for col , output_col in zip ( columns , output_columns )}) self . _set_output_df ( data , df )","title":"AbsRule"},{"location":"api/#etlrules.backends.pandas.numeric.RoundRule","text":"Rounds a set of columns to specified decimal places. Basic usage:: 1 2 3 # rounds Col_A to 2dps, Col_B to 0dps and Col_C to 4dps rule = RoundRule({\"Col_A\": 2, \"Col_B\": 0, \"Col_C\": 4}) rule.apply(data) Parameters: Name Type Description Default mapper Mapping[str, int] A dict {column_name: scale} which specifies to round each column to the number of decimal places specified in the scale. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column in the mapper doesn't exist in the input dataframe. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/numeric.py class RoundRule ( UnaryOpBaseRule ): \"\"\" Rounds a set of columns to specified decimal places. Basic usage:: # rounds Col_A to 2dps, Col_B to 0dps and Col_C to 4dps rule = RoundRule({\"Col_A\": 2, \"Col_B\": 0, \"Col_C\": 4}) rule.apply(data) Args: mapper: A dict {column_name: scale} which specifies to round each column to the number of decimal places specified in the scale. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column in the mapper doesn't exist in the input dataframe. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , mapper : Mapping [ str , int ], named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert all ( isinstance ( col , str ) and isinstance ( scale , ( int , float )) and int ( scale ) >= 0 for col , scale in mapper . items ()), \"Mapper is a {column_name: precision} where column names are strings and precision is an int or float and >=0.\" self . mapper = { col : int ( scale ) for col , scale in mapper . items ()} def apply ( self , data ): df = self . _get_input_df ( data ) if self . strict : if not set ( self . mapper . keys ()) <= set ( df . columns ): raise MissingColumnError ( f \"Column(s) { set ( self . mapper . keys ()) - set ( df . columns ) } are missing from the input dataframe.\" ) mapper = self . mapper else : mapper = { col : scale for col , scale in self . mapper . items () if col in df . columns } df = df . round ( mapper ) self . _set_output_df ( data , df )","title":"RoundRule"},{"location":"api/#etlrules.backends.pandas.strings","text":"","title":"strings"},{"location":"api/#etlrules.backends.pandas.strings.StrCapitalizeRule","text":"Converts a set of string columns to capitalize. Capitalization will convert the first letter in the string to upper case and the rest of the letters to lower case. Basic usage:: 1 2 rule = StrCapitalizeRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to capitalize. required output_columns Optional[Iterable[str]] A list of new names for the columns with the capitalized values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the capitalized values. If not provided, the result is updated in place. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrCapitalizeRule ( BaseAssignRule ): \"\"\" Converts a set of string columns to capitalize. Capitalization will convert the first letter in the string to upper case and the rest of the letters to lower case. Basic usage:: rule = StrCapitalizeRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to capitalize. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the capitalized values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the capitalized values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def do_apply ( self , col ): return col . str . capitalize ()","title":"StrCapitalizeRule"},{"location":"api/#etlrules.backends.pandas.strings.StrExtractRule","text":"Extract substrings from strings columns using regular expressions. Basic usage:: 1 2 3 4 5 6 7 8 9 # extracts the number between start_ and _end # ie: for an input value of start_1234_end - will extract 1234 in col_A rule = StrExtractRule([\"col_A\"], regular_expression=r\"start_([\\d]*)_end\") rule.apply(data) # extracts with multiple groups, extracting the single digit at the end as well # for an input value of start_1234_end_9, col_1 will extract 1234, col_2 will extract 9 rule = StrExtractRule([\"col_A\"], regular_expression=r\"start_([\\d]*)_end_([\\d])\", output_columns=[\"col_1\", \"col_2\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required regular_expression str The regular expression used to extract data. The regular expression must have 1 or more groups - ie sections between brackets. The groups do the actual extraction of data. If there is a single group, then the column can be modified in place (ie no output_columns are needed) but if there are multiple groups, then output_columns must be specified as each group will be extracted in a new output column. required keep_original_value bool Only used in case there isn't a match and it specifies if NA should be used in the output or the original value. Defaults: True. If the regular expression has multiple groups and therefore multiple output_columns, only the first output column will keep the original value, the rest will be populated with NA. False output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, it must have one output_column per regular expression group, for every input columns. For example, if input column is [\"A\"] and the regular expression is \"a_([\\d]) ([\\d])\" with 2 groups, then the output columns must have 2 columns (one per group) - for example [\"A1_out\", \"A2_out\"]. If the input columns are [\"A\", \"B\"] and the regular expression is \"a ([\\d])_([\\d])\" with 2 groups, then the output columns must have 2 columns (one per group) for every input column - e.g. [\"A1_out\", \"A2_out\", \"B1_out\", \"B2_out\"]. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place (only possible if the regular expression has a single group). None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrExtractRule ( UnaryOpBaseRule , ColumnsInOutMixin ): r \"\"\" Extract substrings from strings columns using regular expressions. Basic usage:: # extracts the number between start_ and _end # ie: for an input value of start_1234_end - will extract 1234 in col_A rule = StrExtractRule([\"col_A\"], regular_expression=r\"start_([\\d]*)_end\") rule.apply(data) # extracts with multiple groups, extracting the single digit at the end as well # for an input value of start_1234_end_9, col_1 will extract 1234, col_2 will extract 9 rule = StrExtractRule([\"col_A\"], regular_expression=r\"start_([\\d]*)_end_([\\d])\", output_columns=[\"col_1\", \"col_2\"]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. regular_expression: The regular expression used to extract data. The regular expression must have 1 or more groups - ie sections between brackets. The groups do the actual extraction of data. If there is a single group, then the column can be modified in place (ie no output_columns are needed) but if there are multiple groups, then output_columns must be specified as each group will be extracted in a new output column. keep_original_value: Only used in case there isn't a match and it specifies if NA should be used in the output or the original value. Defaults: True. If the regular expression has multiple groups and therefore multiple output_columns, only the first output column will keep the original value, the rest will be populated with NA. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, it must have one output_column per regular expression group, for every input columns. For example, if input column is [\"A\"] and the regular expression is \"a_([\\d])_([\\d])\" with 2 groups, then the output columns must have 2 columns (one per group) - for example [\"A1_out\", \"A2_out\"]. If the input columns are [\"A\", \"B\"] and the regular expression is \"a_([\\d])_([\\d])\" with 2 groups, then the output columns must have 2 columns (one per group) for every input column - e.g. [\"A1_out\", \"A2_out\", \"B1_out\", \"B2_out\"]. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place (only possible if the regular expression has a single group). named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , columns : Iterable [ str ], regular_expression : str , keep_original_value : bool = False , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . columns = [ col for col in columns ] self . output_columns = [ out_col for out_col in output_columns ] if output_columns else None self . regular_expression = regular_expression self . _compiled_expr = re . compile ( regular_expression ) groups = self . _compiled_expr . groups assert groups > 0 , \"The regular expression must have at least 1 group - ie a secstion in () - which gets extracted.\" if groups == 1 and self . output_columns is not None : assert len ( self . output_columns ) == len ( self . columns ), \"The regular expression has one group and the output_columns must match 1 to 1 the length of the columns\" if groups > 1 : assert self . output_columns is not None , f \"The regular expression has { groups } groups in which case the output_columns must be specified.\" assert len ( self . output_columns ) == groups * len ( self . columns ), f \"The regular expression has { groups } groups, the output_columns must have { groups } columns per each input column.\" self . keep_original_value = keep_original_value def apply ( self , data ): df = self . _get_input_df ( data ) columns , output_columns = self . validate_columns_in_out ( df , self . columns , self . output_columns , self . strict , validate_length = False ) new_cols_dict = {} groups = self . _compiled_expr . groups for idx , col in enumerate ( columns ): new_col = df [ col ] . str . extract ( self . _compiled_expr , expand = True ) if self . keep_original_value : # only the first new column keeps the value (in case of multiple groups) new_col [ 0 ] . fillna ( value = df [ col ], inplace = True ) for group in range ( groups ): new_cols_dict [ output_columns [ idx * groups + group ]] = new_col [ group ] df = df . assign ( ** new_cols_dict ) self . _set_output_df ( data , df )","title":"StrExtractRule"},{"location":"api/#etlrules.backends.pandas.strings.StrLowerRule","text":"Converts a set of string columns to lower case. Basic usage:: 1 2 rule = StrLowerRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to lower case. required output_columns Optional[Iterable[str]] A list of new names for the columns with the lower case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the lower case values. If not provided, the result is updated in place. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrLowerRule ( BaseAssignRule ): \"\"\" Converts a set of string columns to lower case. Basic usage:: rule = StrLowerRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to lower case. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the lower case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the lower case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def do_apply ( self , col ): return col . str . lower ()","title":"StrLowerRule"},{"location":"api/#etlrules.backends.pandas.strings.StrPadRule","text":"Makes strings of a given width (justifies) by padding left, right or both sides with a fill character. Basic usage:: 1 2 rule = StrPadRule([\"col_A\", \"col_B\", \"col_C\"], width=8, fill_character=\".\", how=\"right\") rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required width int Pad with the fill_character to this width. required fill_character str Character to fill with. Defaults to whitespace. required how Literal['left', 'right', 'both'] How should the stripping be done. One of left, right, both. Left pads at the beggining of the string, right pads at the end, while both pads at both ends. 'both' output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrPadRule ( BaseAssignRule ): \"\"\" Makes strings of a given width (justifies) by padding left, right or both sides with a fill character. Basic usage:: rule = StrPadRule([\"col_A\", \"col_B\", \"col_C\"], width=8, fill_character=\".\", how=\"right\") rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. width: Pad with the fill_character to this width. fill_character: Character to fill with. Defaults to whitespace. how: How should the stripping be done. One of left, right, both. Left pads at the beggining of the string, right pads at the end, while both pads at both ends. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" PAD_LEFT = 'left' PAD_RIGHT = 'right' PAD_BOTH = 'both' def __init__ ( self , columns : Iterable [ str ], width : int , fill_character : str , how : Literal [ PAD_LEFT , PAD_RIGHT , PAD_BOTH ] = PAD_BOTH , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert how in ( self . PAD_LEFT , self . PAD_RIGHT , self . PAD_BOTH ), f \"Unknown how parameter { how } . It must be one of: { ( self . PAD_LEFT , self . PAD_RIGHT , self . PAD_BOTH ) } \" self . how = how self . width = width self . fill_character = fill_character def do_apply ( self , col ): if self . how == self . PAD_RIGHT : return col . str . ljust ( self . width , fillchar = self . fill_character ) elif self . how == self . PAD_LEFT : return col . str . rjust ( self . width , fillchar = self . fill_character ) return col . str . center ( self . width , fillchar = self . fill_character )","title":"StrPadRule"},{"location":"api/#etlrules.backends.pandas.strings.StrSplitRejoinRule","text":"Splits a string into an array of substrings based on a string separator or a regular expression, then rejoin with a new separator, optionally sorting the substrings. Note The output is an array of substrings which can optionally be limited via the limit parameter to only include the first number of substrings. Basic usage:: 1 2 3 4 # splits col_A, col_B, col_C on , # \"b,d;a,c\" will be split and rejoined as \"b|c|d;a\" rule = StrSplitRejoinRule([\"col_A\", \"col_B\", \"col_C\"], separator=\",\", new_separator=\"|\", sort=\"ascending\") rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required separator Optional[str] A literal value to split the string by. Optional. None separator_regex Optional[str] A regular expression to split the string by. Optional Note: One and only one of separator or separator_regex must be specified. None limit Optional[int] A limit to the number of substrings. If specified, only the first substrings are returned plus an additional remainder. At most, limit + 1 substrings are returned with the last beind the remainder. None new_separator str A new separator used to rejoin the substrings. ',' sort Optional[Literal['ascending', 'descending']] Optionally sorts the substrings before rejoining using the new_separator. It can be set to either ascending or descending, sorting the substrings accordingly. When the value is set to None, there is no sorting. None output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrSplitRejoinRule ( BaseAssignRule ): \"\"\" Splits a string into an array of substrings based on a string separator or a regular expression, then rejoin with a new separator, optionally sorting the substrings. Note: The output is an array of substrings which can optionally be limited via the limit parameter to only include the first <limit> number of substrings. Basic usage:: # splits col_A, col_B, col_C on , # \"b,d;a,c\" will be split and rejoined as \"b|c|d;a\" rule = StrSplitRejoinRule([\"col_A\", \"col_B\", \"col_C\"], separator=\",\", new_separator=\"|\", sort=\"ascending\") rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. separator: A literal value to split the string by. Optional. separator_regex: A regular expression to split the string by. Optional Note: One and only one of separator or separator_regex must be specified. limit: A limit to the number of substrings. If specified, only the first <limit> substrings are returned plus an additional remainder. At most, limit + 1 substrings are returned with the last beind the remainder. new_separator: A new separator used to rejoin the substrings. sort: Optionally sorts the substrings before rejoining using the new_separator. It can be set to either ascending or descending, sorting the substrings accordingly. When the value is set to None, there is no sorting. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" SORT_ASCENDING = \"ascending\" SORT_DESCENDING = \"descending\" def __init__ ( self , columns : Iterable [ str ], separator : Optional [ str ] = None , separator_regex : Optional [ str ] = None , limit : Optional [ int ] = None , new_separator : str = \",\" , sort : Optional [ Literal [ SORT_ASCENDING , SORT_DESCENDING ]] = None , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert bool ( separator ) != bool ( separator_regex ), \"One and only one of separator and separator_regex can be specified.\" self . separator = separator self . separator_regex = separator_regex self . _compiled_regex = re . compile ( self . separator_regex ) if self . separator_regex is not None else None self . limit = limit assert isinstance ( new_separator , str ) and new_separator self . new_separator = new_separator assert sort in ( None , self . SORT_ASCENDING , self . SORT_DESCENDING ) self . sort = sort def do_apply ( self , col ): if self . separator_regex is not None : new_col = col . str . split ( pat = self . _compiled_regex , n = self . limit , regex = True ) else : new_col = col . str . split ( pat = self . separator , n = self . limit , regex = False ) new_separator = self . new_separator if self . sort is not None : reverse = self . sort == self . SORT_DESCENDING func = lambda val : new_separator . join ( sorted ( val , reverse = reverse )) if val not in ( nan , NA , None ) else val else : func = lambda val : new_separator . join ( val ) if val not in ( nan , NA , None ) else val return new_col . apply ( func )","title":"StrSplitRejoinRule"},{"location":"api/#etlrules.backends.pandas.strings.StrSplitRule","text":"Splits a string into an array of substrings based on a string separator or a regular expression. Note The output is an array of substrings which can optionally be limited via the limit parameter to only include the first number of substrings. If you need the output to be a string, perhaps joined on a different separator and optionally sorted then use the StrSplitRejoinRule rule. Basic usage:: 1 2 3 4 5 6 7 8 9 # splits col_A, col_B, col_C on , # \"a,b;c,d\" will be split as [\"a\", \"b;c\", \"d\"] rule = StrSplitRule([\"col_A\", \"col_B\", \"col_C\"], separator=\",\") rule.apply(data) # splits col_A, col_B, col_C on either , or ; # \"a,b;c,d\" will be split as [\"a\", \"b\", \"c\", \"d\"] rule = StrSplitRule([\"col_A\", \"col_B\", \"col_C\"], separator_regex=\",|;\") rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required separator Optional[str] A literal value to split the string by. Optional. None separator_regex Optional[str] A regular expression to split the string by. Optional Note: One and only one of separator or separator_regex must be specified. None limit Optional[int] A limit to the number of substrings. If specified, only the first substrings are returned plus an additional remainder. At most, limit + 1 substrings are returned with the last beind the remainder. None output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrSplitRule ( BaseAssignRule ): \"\"\" Splits a string into an array of substrings based on a string separator or a regular expression. Note: The output is an array of substrings which can optionally be limited via the limit parameter to only include the first <limit> number of substrings. If you need the output to be a string, perhaps joined on a different separator and optionally sorted then use the StrSplitRejoinRule rule. Basic usage:: # splits col_A, col_B, col_C on , # \"a,b;c,d\" will be split as [\"a\", \"b;c\", \"d\"] rule = StrSplitRule([\"col_A\", \"col_B\", \"col_C\"], separator=\",\") rule.apply(data) # splits col_A, col_B, col_C on either , or ; # \"a,b;c,d\" will be split as [\"a\", \"b\", \"c\", \"d\"] rule = StrSplitRule([\"col_A\", \"col_B\", \"col_C\"], separator_regex=\",|;\") rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. separator: A literal value to split the string by. Optional. separator_regex: A regular expression to split the string by. Optional Note: One and only one of separator or separator_regex must be specified. limit: A limit to the number of substrings. If specified, only the first <limit> substrings are returned plus an additional remainder. At most, limit + 1 substrings are returned with the last beind the remainder. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def __init__ ( self , columns : Iterable [ str ], separator : Optional [ str ] = None , separator_regex : Optional [ str ] = None , limit : Optional [ int ] = None , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert bool ( separator ) != bool ( separator_regex ), \"One and only one of separator and separator_regex can be specified.\" self . separator = separator self . separator_regex = separator_regex self . _compiled_regex = re . compile ( self . separator_regex ) if self . separator_regex is not None else None self . limit = limit def do_apply ( self , col ): if self . separator_regex is not None : return col . str . split ( pat = self . _compiled_regex , n = self . limit , regex = True ) return col . str . split ( pat = self . separator , n = self . limit , regex = False )","title":"StrSplitRule"},{"location":"api/#etlrules.backends.pandas.strings.StrStripRule","text":"Strips leading, trailing or both whitespaces or other characters from given columns. Basic usage:: 1 2 rule = StrStripRule([\"col_A\", \"col_B\", \"col_C\"], how=\"both\") rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required how Literal['left', 'right', 'both'] How should the stripping be done. One of left, right, both. Left strips leading characters, right trailing characters and both at both ends. 'both' characters Optional[str] If set, it contains a list of characters to be stripped. When not specified or when set to None, whitespace is removed. None output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. None named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrStripRule ( BaseAssignRule ): \"\"\" Strips leading, trailing or both whitespaces or other characters from given columns. Basic usage:: rule = StrStripRule([\"col_A\", \"col_B\", \"col_C\"], how=\"both\") rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. how: How should the stripping be done. One of left, right, both. Left strips leading characters, right trailing characters and both at both ends. characters: If set, it contains a list of characters to be stripped. When not specified or when set to None, whitespace is removed. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" STRIP_LEFT = 'left' STRIP_RIGHT = 'right' STRIP_BOTH = 'both' def __init__ ( self , columns : Iterable [ str ], how : Literal [ STRIP_LEFT , STRIP_RIGHT , STRIP_BOTH ] = STRIP_BOTH , characters : Optional [ str ] = None , output_columns : Optional [ Iterable [ str ]] = None , named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): super () . __init__ ( columns = columns , output_columns = output_columns , named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) assert how in ( self . STRIP_BOTH , self . STRIP_LEFT , self . STRIP_RIGHT ), f \"Unknown how parameter { how } . It must be one of: { ( self . STRIP_BOTH , self . STRIP_LEFT , self . STRIP_RIGHT ) } \" self . how = how self . characters = characters or None def do_apply ( self , col ): if self . how == self . STRIP_BOTH : return col . str . strip ( to_strip = self . characters ) elif self . how == self . STRIP_RIGHT : return col . str . rstrip ( to_strip = self . characters ) return col . str . lstrip ( to_strip = self . characters )","title":"StrStripRule"},{"location":"api/#etlrules.backends.pandas.strings.StrUpperRule","text":"Converts a set of string columns to upper case. Basic usage:: 1 2 rule = StrUpperRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Parameters: Name Type Description Default columns Iterable[str] A list of string columns to convert to upper case. required output_columns Optional[Iterable[str]] A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. required named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. required name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. required description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. required strict bool When set to True, the rule does a stricter valiation. Default: True required Exceptions: Type Description MissingColumnError raised in strict mode only if a column doesn't exist in the input dataframe. ValueError raised if output_columns is provided and not the same length as the columns parameter. Note In non-strict mode, missing columns are ignored. Source code in etlrules/backends/pandas/strings.py class StrUpperRule ( BaseAssignRule ): \"\"\" Converts a set of string columns to upper case. Basic usage:: rule = StrUpperRule([\"col_A\", \"col_B\", \"col_C\"]) rule.apply(data) Args: columns (Iterable[str]): A list of string columns to convert to upper case. output_columns (Optional[Iterable[str]]): A list of new names for the columns with the upper case values. Optional. If provided, if must have the same length as the columns sequence. The existing columns are unchanged, and new columns are created with the upper case values. If not provided, the result is updated in place. named_input (Optional[str]): Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output (Optional[str]): Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name (Optional[str]): Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description (Optional[str]): Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict (bool): When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: raised in strict mode only if a column doesn't exist in the input dataframe. ValueError: raised if output_columns is provided and not the same length as the columns parameter. Note: In non-strict mode, missing columns are ignored. \"\"\" def do_apply ( self , col ): return col . str . upper ()","title":"StrUpperRule"},{"location":"api/#etlrules.backends.pandas.types","text":"","title":"types"},{"location":"api/#etlrules.backends.pandas.types.TypeConversionRule","text":"Converts the type of a given set of columns to other types. Parameters: Name Type Description Default mapper Mapping[str, str] A dict with columns names as keys and the new types as values. required named_input Optional[str] Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. None named_output Optional[str] Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. None name Optional[str] Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. None description Optional[str] Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. None strict bool When set to True, the rule does a stricter valiation. Default: True True Exceptions: Type Description MissingColumnError is raised when a column specified in the mapper doesn't exist in the input data frame. UnsupportedTypeError is raised when an unknown type is speified in the values of the mapper. Source code in etlrules/backends/pandas/types.py class TypeConversionRule ( UnaryOpBaseRule ): \"\"\" Converts the type of a given set of columns to other types. Args: mapper: A dict with columns names as keys and the new types as values. named_input: Which dataframe to use as the input. Optional. When not set, the input is taken from the main output. Set it to a string value, the name of an output dataframe of a previous rule. named_output: Give the output of this rule a name so it can be used by another rule as a named input. Optional. When not set, the result of this rule will be available as the main output. When set to a name (string), the result will be available as that named output. name: Give the rule a name. Optional. Named rules are more descriptive as to what they're trying to do/the intent. description: Describe in detail what the rules does, how it does it. Optional. Together with the name, the description acts as the documentation of the rule. strict: When set to True, the rule does a stricter valiation. Default: True Raises: MissingColumnError: is raised when a column specified in the mapper doesn't exist in the input data frame. UnsupportedTypeError: is raised when an unknown type is speified in the values of the mapper. \"\"\" SUPPORTED_TYPES = { 'int32' , 'int64' , 'float64' , 'str' , } def __init__ ( self , mapper : Mapping [ str , str ], named_input : Optional [ str ] = None , named_output : Optional [ str ] = None , name : Optional [ str ] = None , description : Optional [ str ] = None , strict : bool = True ): assert isinstance ( mapper , dict ), \"mapper needs to be a dict {column_name:type}\" assert all ( isinstance ( key , str ) and isinstance ( val , str ) for key , val in mapper . items ()), \"mapper needs to be a dict {column_name:type} where the names are str\" super () . __init__ ( named_input = named_input , named_output = named_output , name = name , description = description , strict = strict ) self . mapper = mapper def apply ( self , data ): super () . apply ( data ) df = self . _get_input_df ( data ) columns_set = set ( df . columns ) for column_name , type_str in self . mapper . items (): if column_name not in columns_set : raise MissingColumnError ( f \"Column ' { column_name } ' is missing in the data frame. Available columns: { sorted ( columns_set ) } \" ) if type_str not in self . SUPPORTED_TYPES : raise UnsupportedTypeError ( f \"Type ' { type_str } ' for column ' { column_name } ' is not currently supported.\" ) df = df . assign ( ** { column_name : df [ column_name ] . astype ( type_str ) for column_name , type_str in self . mapper . items ()}) self . _set_output_df ( data , df )","title":"TypeConversionRule"},{"location":"api/#etlrules.exceptions","text":"","title":"exceptions"},{"location":"api/#etlrules.exceptions.ColumnAlreadyExistsError","text":"An attempt to create a column that already exists in the dataframe. Source code in etlrules/exceptions.py class ColumnAlreadyExistsError ( Exception ): \"\"\" An attempt to create a column that already exists in the dataframe. \"\"\"","title":"ColumnAlreadyExistsError"},{"location":"api/#etlrules.exceptions.ExpressionSyntaxError","text":"A Python expression used to create a column, aggregate or other operations has a syntax error. Source code in etlrules/exceptions.py class ExpressionSyntaxError ( SyntaxError ): \"\"\" A Python expression used to create a column, aggregate or other operations has a syntax error. \"\"\"","title":"ExpressionSyntaxError"},{"location":"api/#etlrules.exceptions.MissingColumnError","text":"An operation is being applied to a column that is not present in the input data frame. Source code in etlrules/exceptions.py class MissingColumnError ( Exception ): \"\"\" An operation is being applied to a column that is not present in the input data frame. \"\"\"","title":"MissingColumnError"},{"location":"api/#etlrules.exceptions.SchemaError","text":"An operation needs a certain schema for the dataframe which is not present. Source code in etlrules/exceptions.py class SchemaError ( Exception ): \"\"\" An operation needs a certain schema for the dataframe which is not present. \"\"\"","title":"SchemaError"},{"location":"api/#etlrules.exceptions.UnsupportedTypeError","text":"A type conversion is attempted to a type that is not supported. Source code in etlrules/exceptions.py class UnsupportedTypeError ( Exception ): \"\"\" A type conversion is attempted to a type that is not supported. \"\"\"","title":"UnsupportedTypeError"},{"location":"api/#etlrules.rule","text":"","title":"rule"},{"location":"api/#etlrules.rule.BinaryOpBaseRule","text":"Base class for binary operation rules (ie operations taking two data frames as input). Source code in etlrules/rule.py class BinaryOpBaseRule ( BaseRule ): \"\"\" Base class for binary operation rules (ie operations taking two data frames as input). \"\"\" def __init__ ( self , named_input_left , named_input_right , named_output = None , name = None , description = None , strict = True ): super () . __init__ ( named_output = named_output , name = name , description = description , strict = strict ) assert named_input_left is None or isinstance ( named_input_left , str ) and named_input_left assert named_input_right is None or isinstance ( named_input_right , str ) and named_input_right assert named_input_left != named_input_right self . named_input_left = named_input_left self . named_input_right = named_input_right def _get_input_df_left ( self , data ): if self . named_input_left is None : return data . get_main_output () return data . get_named_output ( self . named_input_left ) def _get_input_df_right ( self , data ): if self . named_input_right is None : return data . get_main_output () return data . get_named_output ( self . named_input_right )","title":"BinaryOpBaseRule"},{"location":"api/#etlrules.rule.UnaryOpBaseRule","text":"Base class for unary operation rules (ie operations taking a single data frame as input). Source code in etlrules/rule.py class UnaryOpBaseRule ( BaseRule ): \"\"\" Base class for unary operation rules (ie operations taking a single data frame as input). \"\"\" def __init__ ( self , named_input = None , named_output = None , name = None , description = None , strict = True ): super () . __init__ ( named_output = named_output , name = name , description = description , strict = strict ) assert named_input is None or isinstance ( named_input , str ) and named_input self . named_input = named_input def _get_input_df ( self , data ): if self . named_input is None : return data . get_main_output () return data . get_named_output ( self . named_input )","title":"UnaryOpBaseRule"},{"location":"authors/","text":"Credits \u00b6 Development Lead \u00b6 Ciprian Miclaus https://github.com/ciprianmiclaus Contributors \u00b6 None yet. Why not be the first?","title":"Authors"},{"location":"authors/#credits","text":"","title":"Credits"},{"location":"authors/#development-lead","text":"Ciprian Miclaus https://github.com/ciprianmiclaus","title":"Development Lead"},{"location":"authors/#contributors","text":"None yet. Why not be the first?","title":"Contributors"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/ciprianmiclaus/etlrules/issues. If you are reporting a bug, please include: Your operating system name and version. Python version, pandas version Any other details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug (a test case is ideal). Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 ETLrules could always use more documentation, whether as part of the official ETLrules docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/ciprianmiclaus/etlrules/issues. If you are proposing a feature: Start with the problem statement (the pain point, what problem are you trying to solve) Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up etlrules for local development. Fork the etlrules repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/etlrules.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8, 3.9 and for PyPy. Check https://github.com/ciprianmiclaus/etlrules/actions and make sure that the tests pass for all supported Python versions. Tips``` \u00b6 1 $ pytest tests/ ```To run a the tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run: 1 2 3 $ poetry patch # possible: major / minor / patch $ git push $ git push --tags Github Actions will then deploy to PyPI if tests pass.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/ciprianmiclaus/etlrules/issues. If you are reporting a bug, please include: Your operating system name and version. Python version, pandas version Any other details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug (a test case is ideal).","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"ETLrules could always use more documentation, whether as part of the official ETLrules docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/ciprianmiclaus/etlrules/issues. If you are proposing a feature: Start with the problem statement (the pain point, what problem are you trying to solve) Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up etlrules for local development. Fork the etlrules repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/etlrules.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8, 3.9 and for PyPy. Check https://github.com/ciprianmiclaus/etlrules/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"1 $ pytest tests/ ```To run a the tests.","title":"Tips```"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run: 1 2 3 $ poetry patch # possible: major / minor / patch $ git push $ git push --tags Github Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"history/","text":"History \u00b6 0.1.0 (2023-09-07) \u00b6 First release on PyPI.","title":"History"},{"location":"history/#history","text":"","title":"History"},{"location":"history/#010-2023-09-07","text":"First release on PyPI.","title":"0.1.0 (2023-09-07)"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install ETLrules, run this command in your terminal: 1 pip install etlrules This is the preferred method to install ETLrules, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for ETLrules can be downloaded from the Github repo . You can either clone the public repository: 1 git clone git://github.com/ciprianmiclaus/etlrules Or download the tarball : 1 curl -OJL https://github.com/ciprianmiclaus/etlrules/tarball/master Once you have a copy of the source, you can install it with: 1 pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install ETLrules, run this command in your terminal: 1 pip install etlrules This is the preferred method to install ETLrules, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for ETLrules can be downloaded from the Github repo . You can either clone the public repository: 1 git clone git://github.com/ciprianmiclaus/etlrules Or download the tarball : 1 curl -OJL https://github.com/ciprianmiclaus/etlrules/tarball/master Once you have a copy of the source, you can install it with: 1 pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 To use ETLrules in a project 1 import etlrules","title":"Usage"},{"location":"usage/#usage","text":"To use ETLrules in a project 1 import etlrules","title":"Usage"}]}